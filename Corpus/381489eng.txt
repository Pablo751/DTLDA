1 
IFAP-2021/Report AI4IA1 Table of Contents  
1. The Executive Summary  ................................ ................................ ................................ .. 3 
2. Introduction  ................................ ................................ ................................ ....................  5 
3. General overview and acknowledgement  ................................ ................................ ...... 5 
3.1. Popular themes raised  ................................ ................................ ................................  6 
3.2. Frequent AI4IA Themes  ................................ ................................ ...............................  7 
3.3. AI4IA Risks and Cha llenges  ................................ ................................ ..........................  8 
4. Welcoming, UNESCO Opening and Keynote Addresses  ................................ ...............  13 
4.1. Welcoming Address ................................ ................................ ................................ ... 13 
4.2. UNESCO Opening Addresses  ................................ ................................ .....................  14 
4.2.1.  UNESCO Cluster Office for Southern Africa  ................................ .......................  14 
4.2.2.  UNESCO Cluster Office for the Caribbean  ................................ .........................  15 
5. Keynote Presentations  ................................ ................................ ................................ .. 17 
5.1. Shri Abhishek Singh  ................................ ................................ ...............................  17 
5.2. Pansy Tlakula  ................................ ................................ ................................ .........  18 
6. Thematic Areas  ................................ ................................ ................................ .............  20 
7. AI Policy and Ethics  ................................ ................................ ................................ .......  21 
7.1. Introduction ................................ ................................ ................................ ...............  21 
7.2. Overview of presenters  ................................ ................................ .............................  24 
8. AI and Society  ................................ ................................ ................................ ................  37 
8.1. Introduction ................................ ................................ ................................ ...............  37 
8.2. Overview of presenters  ................................ ................................ .............................  40 
9. AI and Healthcare ................................ ................................ ................................ ..........  56 
9.1. Introduction ................................ ................................ ................................ ...............  56 
10. Media and the Right to Know  ................................ ................................ ............................  59 
10.1. Introduction ................................ ................................ ................................ .................  59 2 
 10.2. Overview of presenters  ................................ ................................ ...............................  62 
11. AI & Law ................................ ................................ ................................ .....................  76 
11.1.  Introd uction  ................................ ................................ ................................ ...........  76 
11.2.  Overview of presenters  ................................ ................................ .........................  78 
12. AI, Big Data and Innovation  ................................ ................................ ...............................  88 
12.1. Introduction ................................ ................................ ................................ .................  88 
13. AI and Creativity  ................................ ................................ ................................ ............  97 
13.1.  Introduction  ................................ ................................ ................................ ...........  97 
13.2.  Overview of presenters  ................................ ................................ .........................  98 
14. Youth in AI  ................................ ................................ ................................ ...................  106 
14.1.  Introduction  ................................ ................................ ................................ .........  106 
14.2.  Overview of presenters  ................................ ................................ .......................  108 
15. Accessibility Pavilion  ................................ ................................ ................................ ... 115 
15.1.  Introduction  ................................ ................................ ................................ .........  115 
15.2.  Overview  ................................ ................................ ................................ ..............  115 
16. Conference Organisers  ................................ ................................ ................................ ..... 118 
17.Conference Volunteers  ................................ ................................ ................................ ..... 119 
 
 
Disclaimer : The views summarized in this Conference Report are meant to reflect those of the 
presenters and should not be attributed to UNESCO, the UNESCO IFAP Working Group on Information 
Accessibility (WGIA), or members of the WGIA.  
 
 3 
 1. The Executive Summary  
 
On 28th September 2021, the Artificial Intelligence for Information Accessibility (AI4IA) Conference 
explored nine themes on the promotion of accessibility by AI. These themes were: AI Policy and Ethics, 
AI and Society, AI and Healthcare, Media and the Rig ht to Know, AI & Law, AI & Big Data and 
Innovation, AI and Creativity, Youth in AI, and the Accessibility Pavilion. The conference was a platform 
for more than 73 presenters from 17 countries to contribute to each of these AI4IA thematic areas in 
their uni que and diverse ways.  
The thematic session on AI Policy and Ethics captured the central concerns on AI for Information 
Accessibility. Eleven presenters from India, Egypt, South Africa, France, the United Kingdom, the 
United States of America, Canada, and Brazil, showcased the complexities of policy development and 
ethical considerations while representing the global diversity this conference sought to celebrate.  
The AI and Society theme had thirteen presenters who explored notions of law, multi -stakeholde r and 
multi -sectoral responsibilities, the features of future AI societies and the recommendations for 
bridging divides. The global representation was excellent, coming from Jamaica, Mexico, the United 
States of America, Canada, Germany, and Uganda.  
The A I Health market has progressively increased from 2014 to 2021, and it will only continue to 
grow.  
4 
 Though Lt. Gen. Velu Nair was the sole presenter in the AI and Healthcare theme, this topic arose quite 
frequently in other themes as well. This was due to th e prevalence of AI being embedded in health 
care operations, especially during the Covid -19 Pandemic. This session critically engaged with medical 
practitioners, AI and their roles and responsibilities in healthcare in both complementary and 
divergent ways . We saw how AI impacts healthcare, especially due to the availability of big (medical) 
data on a vast collection of health -related data and learnt that by utilising this data, deep learning can 
solve complex problems to guide better healthcare options. It  was also seen that the AI health market 
has progressively increased from 2014 to 2021, and it will only continue to grow. As a result, one can 
also see an increase in academic publications.  
The next theme was Media and the Right to Know. This session show cased the role of the media and 
the right to know during ten presentations – from the United States of America, Brazil, Colombia, 
Jamaica, United Kingdom, India, Zambia, and South Africa. It explored the role of AI ethics and 
Accessibility considerations h aving an impact on public relations, communications, and reputation and 
the topic of fake news, which is also relevant to the right to know and reputation.  
Also considered was how AI could be used to improve legislative decision -making.  
Could an Artificial  Intelligence be seen as an inventor or originator of something, and if so, what might 
the legal implications be? Nine presenters from Brazil, the United States of America, France, and India 
answered this question and explored the AI and Law session. Addit ionally, the presenters discussed 
the malicious uses of AI insofar as it can be used for cybercrimes that ought to be punishable by law 
and how AI can be used to improve legislative decision -making.  
The thematic area of AI, Big Data and Innovation explored  innovative and creative ways in which AI 
can be used to streamline and improve processes across a diverse representation of sectors. Six 
presentations from the United States of America, Canada, Chile, Germany, South Africa, and Turkey 
dove into the opport unities and challenges AI provides in this sector.  
Moreover, five presentations from the United States of America, Canada, Jamaica, and Israel 
introduced us to the Creative scope of AI and the endless possibilities it contains to visualise the 
design, com pose music and test our boundaries of comedy and woke culture. Presenters answered 
questions on whether algorithms can be creative, and how AI can be used to promote human 
creativity and provide new avenues for creative expression.  5 
 2. Introduction  
 
3. General o verview and acknowledgement  
The UNESCO Information For All Programme (IFAP) Working Group on Information Accessibility 
(WGIA), hosted its second online one -day conference on 28 September 2021. This event was hosted 
in collaboration with the Kule In stitute for Advanced Studies (KIAS) and AI for Society (AI4S) Signature 
Area, both at the University of Alberta, Canada; the International Centre for Information Ethics (ICIE); 
Future Africa at the University of Pretoria, South Africa; the Centre for New E conomic Diplomacy 
(CNED) in ORF, India; and the Broadcasting Commission of Jamaica. It was organised under the 
auspices of the UNESCO Cluster Office for the Caribbean, Kingston, Jamaica and the UNESCO Regional 
Office for Southern Africa, Harare, Zimbabwe.  
The conference was organised to commemorate the International Day for Universal Access to 
Information (IDUAI) 2021 under the global theme, “What We Know about Our Right to Know" and in 
the context of the COVID -19 pandemic, “The Right to Know - Build ing Back Better with Access to 
Information." The theme of the conference covered Inclusive AI and addressed Information 
Accessibility.  
6 
 International Day for Universal Access to Information focused on the right to information in times of 
crisis and  on the advantages of having constitutional, statutory and/or policy guarantees for public 
access to information to save lives, build trust and help the formulation of sustainable policies through 
and beyond the COVID -19 crisis.  
The theme of the conference  was Inclusive AI with topics addressing information accessibility.  
The aim of this specific event was on promoting, and also understanding, the barriers to inclusive 
artificial intelligence. Sure, AI can be beneficial to society, but it can also y ield harmful effects if abused. 
Therefore, the theme discussed a range of issues, including the relationship between Artificial 
Intelligence (AI) and Law, AI and Ethics, Media and our Right to know, Creativity and Innovation and 
how necessary it is to comp rehend how AI can be made inclusive, thereby benefiting the widest cross -
sections of society.  
This event provided a platform for open discourse involving participants from academia, civil society, 
private sector, and government. In recognition of t he central theme guiding the event – Accessibility 
– the AI4IA promoted accessibility in a number of ways. The conference organisers, partners and 
volunteers ensured that all the pre -recorded presentations were closed -captioned for those hard of 
hearing. I n addition, volunteers were present throughout the saloon sessions to assist delegates and 
participants of the AI4IA Conference. The conference departed from the usual Zoom or MS Team 
interface which may preclude a variety of users and used a more interact ive Gather .Town platform 
providing for alternative virtual conference engagements. An expression of gratitude is also to be 
conveyed to the international sign language expert - Mr. Andries van Niekerk from the National 
Institute of the Deaf, South Africa - who provided interpretation in international sign language. 
Together with his real -time sign interpretation, captioned versions of Ms.Monica Desai and Mr.Colton 
Bishop’s presentations were also provided to facilitate greater accessibility to viewers who ma y be 
deaf or hard of hearing.  
 
3.1. Popular themes raised  
• AI is ubiquitous  
• The rapid development of technologies  
• The necessity of policies, guidelines, regulations and legislation (which take slower than the 
development of technologies)  7 
 • Promotion of various literacies, including AI, digital, media and information literacy  
• Responsibility of big technology companies and governments  
• Role of intergovernmental and international cooperation  
• Enforcement of racial, ethnic, religious and gender bi as 
• AI brings both opportunities and challenges  
• Efforts must be made to fight against mis -dis- and mal -information, fake news, filter bubbles 
and echo chambers  
• Colonisation of data  
• Users, legislators, researchers, journalists – all sectors of society – must  be informed of, and 
understand how these technologies work.  
 
3.2. Frequent AI4IA Themes  
• Ethics  
• Fairness  
• Openness  
• Transparency  
• Privacy  
• Net-neutrality  
• Promotion of democratic societies  
• Freedom of expression  
• Diversity  
• Inclusion  
• Accountability  
• Responsibility of developers  
 8 
 3.3. AI4IA Risks and Challenges  
• Threats to societal interests  
• Treats to the environment  
• Threats to democracy  
• Systemic risks  
Overview of speakers ’ statistics  
 
Images taken from the Gather.Town platform  
 
1 - Figure 1: Salon B  
9 
  
2 - Figure 2: Presentation by Lt Gen V Nair - AI and Healthcare  
 
 
3 - Figure 3: Presentation by Shri Abishek Singh  
10 
  
• Figure  4: Presentation by Monica Desai  
 
 
4 - Figure 5: Main Conference Hall for Keynote Presentations  
11 
  
5 - Figure 6: Room 6 Discussions  
 
6 - Figure 7: Room 7 discussions  
 
12 
  
7 - Figure 8: Meeting hall discussions  
 
8 - Figure 9: Meeting hall discussions  
 
Disclaimer : The views summarized in this Conference Report are meant to reflect those of the 
presenters and should not be attributed to UNESCO, the UNESCO IFAP Working Group on Information 
Accessibility (WGIA), or members of the WGIA.  
13 
 4. Welcoming, UNESCO Opening and K eynote Addresses  
 
 
4.1. Welcoming Address  
Cordel Green and Samridhi Arora  [1]  
Cordel Green, Executive Director of the Broadcasting Commission of Jamaica, and Chair of the IFAP 
Working Group on Information Accessibility welcomed all the participants to the Second Artificial 
Intelligence for Information Accessibility  (AI4IA) Conferenc e, held in commemoration of UNESCO ’s 
International Day for Universal Access to Information (IDUAI), the 28th of September. He introduced 
the participants to the on -demand format of the 2021 Conference and shared his views on how it 
allowed for better globa l participation, wider reach and greater inclusivity. Partners, amongst others 
the UNESCO Cluster Office for the Caribbean and the UNESCO Regional Office of Southern Africa, were 
thanked for making this event possible.  
Following Green's welcome, Samridhi A rora - Chair of the AI4IA Planning Committee, Advocate at the 
Supreme Court of India, and member of the UNESCO Working Group on Information Accessibility - 
officially opened the Conference. Since accessibility was the core focus of the conference, Ms Arora 
took the time to introduce the participants to volunteers who had been organised to assist with the 
programme as well as the new and interactive Gather. Town platform. She provided an overview of 
the platform, the rooms, and the thematic areas of the confer ence. Before closing the opening 
14 
 remarks, she extended a sincere appreciation to all the partners, presenters, the WGIA members and 
especially the AI4IA Conference Organising Committee.  
 
References  
[1] https://youtu.be/fDT1vcxKsvI  
 
4.2. UNESCO Opening Address es 
4.2.1.  UNESCO Cluste r Office for Southern Africa  
Presentation by Martiale Zebaze Kana  [2] 
Martiale Zebaze Kana opened his address by reiterating the slogan for the 2021 Conference “The Right 
to Know: Building Back Better with Access to Information ” and highlighting how well i t related to 
artificial intelligence, its capabilities, opportunities and challenges. He discussed the importance of 
promoting literacy, education, and the use of Information and Communication Technologies (ICTs), 
especially in light of the global pandemic  since it has unfortunately precluded many children from 
learning because they lack access to ICTs to attend online learning. He pointed out that being kept out 
of school exacerbates poverty and makes people more vulnerable to mis - and disinformation and f ake 
news but also stated that Artificial Intelligence can play a role in mitigating the spread of such 
disinformation by identifying false information. It can further assist with education by extending 
access to different languages and translating classroo m instructions, whilst also promoting local, 
regional, and international education resource exchanges and collaboration. It automates 
administrative tasks, hence supporting teaching staff to be more effective and efficient in their 
increased duties. It was  brought to the notice of the participants that currently AI had low adoption 
rates across the African continent, but there was an opportunity for states to collaborate to promote 
increased access to and integration of AI technologies. Mr.Kana called upon the states to take a 
proactive stance on the development of policy and adoption of AI and suggested they adopt, and 
adapt to, the technological and Fourth Industrial Revolution. He said that African states can learn from 
the European Union when it comes to  AI policies and laws, but with the development and adoption of 
legislation and policies, it is pertinent for us to avoid stifling innovation. Recommendations for African 
states included:  
• The need to strengthen policy initiatives for AI financing  
• Strea mline the regulatory frameworks for AI  15 
 • Enhancing capacity for AI governance  
Mr Kana concluded that care should be given to updating education, skills, and training systems to 
strengthen human development and protect against algorithmic bias and called up on African states 
to work with UNESCO to promote AI to be used as a tool to benefit the African continent.  
 
4.2.2.  UNESCO Cluster Office for the Caribbean  
Presentation by Saadia Sanchez -Vegas, PhD: Director and Representative UNESCO Cluster Office for 
the Caribbea n 
Saadia Sanchez -Vegas welcomed everyone to the second online AI4IA Conference and acknowledged 
the International Day for Universal Access to Information, observed each year on the 28th of 
September. A special expression of gratitude was given to UNESCO ’s Information For All Programme, 
the Working Group on Information Accessibility for organising the event, as well as the prestigious 
parties who supported this event.  
The 74th UN General Assembly declared the 28th of September as the IDUAI in October 2019 an d that 
the theme for the 2021 conference was “The Right to Know ”. She noted that UNESCO by facilitating a 
global dialogue highlights the role of access to information laws and their implementation to build 
back solid institutions for the public good and su stainable development. It supports international 
collaboration in this field. For the IDUAI, UNESCO and its partners were hosting seven panels:  
• Panel 1: Access to information laws during the decade of actions: trends and challenges;  
• Panel 2: The importance of independence and efficiency of oversight bodies and legal 
frameworks;  
• Panel 3: Leveraging digital technologies for peace and sustainable development;  
• Panel 4: Delivering regionally, delivering for citizens, building the effe ctiveness of access to 
information initiatives;  
• Panel 5: Strengthening the right to access information in the universal periodic review;  
• Panel 6: Access to information – regional perspectives and UNESCO policy guide; and  
• Panel 7: Harne ssing OER to strengthen access to information.  
She pointed out that COVID -19 has raised the need for a global reflection on the impact of access to 
and the quality of information, democratic participation, and the culture of peace. Hence, we should 16 
 reflect  on the impact it has on decision -making and the exercising of human rights. It was also seen 
that along with the social and ethical requirements of access to information by the public, there was 
also increased legal recognition of the right to access to i nformation. While in 1991 only 12 countries 
had laws guaranteeing citizens the right to access government information, the number grew to 
include 40 countries in 2009, and 126 countries in 2019.  
Ms Sanchez also noted the challenges in terms of the inclusio n of international standards. Having 
access underscores the importance of citizens having the opportunity to access information utilizing 
ICT infrastructure, that it is affordable, and that they have the skills to engage with ICTs in a meaningful 
way. Othe r challenges include hate speech and disinformation. There is an urgent call to action for us 
all to tackle these obstacles by joining our efforts and resources to provide more access to technology 
and information, ensuring digital cooperation and transfor mation. Examples of UNESCO ’s projects 
that promote access include the ROAM -X principles as well as the Global Framework for Ethics of 
Artificial Intelligence.  
In essence, we must ensure that we provide a safe, equitable and open digital future for all and leave 
no one behind.  
 
References  
[2] https://www.youtube.com/watch?v=0BeMJQDwWjg  17 
 5. Keynote Presentations  
 
 
5.1. Shri Abhishek Singh  
President and CEO, National E -Governance Division, MyGov and Digital India, Ministry of Electronics 
& IT, Government of India  [3]  
In his keynote address, Shri Abhishek Singh recognised that AI has become part and parcel of our 
everyday lives  (for example NetFlix recommendations). AI has assisted with the COVID -19 chatbot that 
provides useful information to citizens. When the potential of AI is considered, especially in monetary 
and economic terms, it can contribute to the digital economy. He pointed out that India is an excellent 
example of the usage and implementation of AI, such as having one of the largest workforces in AI, 
using Natural Language Processing to assist with language translation for those who do not 
understand English, licence  assistance using voice -based interaction, and agricultural usages.  
 Mr. Singh went on to introduce our participants to The India National Strategy on AI which was 
launched in 2018 with the key focus is to ensure that India emerges as a garag e for the world to store 
AI systems, because of the amount of data that is available due to the large population. The need was 
to ensure adequate capacity, by supporting PhD scholars who can be deployed to work in developing 
18 
 AI solutions. This would allow for building capacity in government. He stated that to investigate the 
future of AI, India is targeting youth and government schools to sign up for the programme to get AI -
based lessons to one day build AI -based solutions. This empowers them to have AI ski lls by the time 
they enter the workforce. Our keynote speaker proceeded to close his speech and envisioned that 
public services will be transformed to be even more accessible and affordable, transforming the lives 
of everyday citizens.  
 
5.2. Pansy Tlakula  
 Information Regulator, South Africa  [4]  
Pansy Tlakula started her speech by recognising the relevancy and importance of the UNESCO IDUAI 
Theme for 2021 and established the ideal of a human right, such as to access information, as an 
enabling ins trument. She stated that as we reflect on COVID -19 and how it has changed our lives, we 
must consider that our experiences also mirror the countries we come from. Not everyone has similar 
access to vaccinations. For example, the Global South is far behind the Global North countries that are 
already deploying booster shots. Thus, it is pertinent that the communities of nations purposely adopt 
a shared mission to promote vaccination accessibility. This must be a right for all, not just those who 
have the fina ncial resources to access it. Human rights -centred economic reforms must be adopted to 
improve the social -economic wellbeing  of people, inclusiveness, and reduce inequality.  
Ms.Tlakula noted that an essential element of the COVID -19 respons e and recovery is to ensure the 
honesty and transparency of public service delivery. To promote integrity in the public sector, 
information disclosure must be considered a norm. States must make it routine practice to open data 
and make information availab le in accessible forms, based on a gold -standard proactive disclosure 
principle and this must be applicable to both public and private institutions. An example of such a gold 
standard is the African Union ’s model law on access to information  [5]. Central t o these efforts is the 
notion that information must be democratised.  
She called upon all role players – government, public and private sector, civil society –to be sensitive 
to inequalities exacerbated by global imbalances and by the develo pment of technologies when 
designing economic recovery programmes. The resource rich should not be the only audible voices.  
 
References  
[3] https://youtu.be/zJLv8sreIiQ  
[4] https://youtu.be/EVlI3ijkwV4  19 
 [5] https://www.achpr.org/legalinstruments/detail?id=32  
 
 
 
 20 
 6. Thematic Areas  
 
The conference consists of the following thematic areas:  
1. AI Policy and Ethics  
2. AI and Society  
3. AI and Healthcare  
4. Media and the right to know  
5. AI and Law  
6. AI, Big Data and Innovation  
7. AI and Creativity  
8. Youth in AI  
9. Accessibility pavilion  
 
The recordings for each of the thematic areas have been made available on YouTube. Upon clicking 
on the theme, you will be able to access the recordings.  
21 
 7. AI Policy and Ethics  
 
7.1. Introduction  
The thematic session on AI Policy and Ethic s [6], was thought -provoking and immediately captured 
the central concerns on AI for Information Accessibility. Eleven presenters showcased not only the 
complexities of policy development and ethical considerations  but also represented the global 
diversity this conference sought to celebrate. The contributions came from India, Egypt, South Africa, 
France, the United Kingdom, the United States of America, Canada, and Brazil.  
Wendell Wallach presented on Ethics, Engin eering and Oversight  and situated his departure in the 
ubiquity of ICTs and emerging technologies, as well as their rapid development and deployment. He 
questioned whose values will shape the trajectory of these developments and while grounding the 
need fo r the development of policy and ethics guidelines in already -existing global initiatives, such as 
the SDGs, OECD AI principles, UNESCO's Ethics of AI draft Recommendations and the IEEE ’s Ethically 
Aligned Design, he further argued that legislation lags. Du e to the slower pace of guidelines, policies 
and legislation, the commodification and politicisation of these technologies vis-à-vis surveillance 
capitalism, the weaponization of digital tools might inevitably drive development. He concluded that 
a value r eset, soft laws and well -designed policies and government reforms can nudge the technology 
trajectory onto a sustainable path.  
22 
 Artificial Intelligence, class, gender and race were Arthur Coelho Bezerra ’s focal points. He succinctly 
stated that information accessibility is closely related to educational accessibility. Taking a step 
further, he argued that educations cost money and that it then becomes the breeding ground for 
deepening inequalities between those who can access quality (paid) information and e ducational 
resources and those who do not have access to those resources. Not even zero -rated websites solve 
these concerns, since they delimit the ability of individuals to visit other websites to verify the accuracy 
and validity of the information they r eceive, which ultimately contributes to the veracity of mis - and 
disinformation whilst embedding echo chambers. Contrary to the usual arguments of access to 
information, Mr Bezerra warned against information dependence and suggested being aware of big 
tech nology companies ’ efforts to encourage addiction to the internet, social media platforms and 
information consumption.  
Yves Poullet presented from a European Union perspective on whether digital platforms require 
regulation. In his presentation, he put a sp ecific focus on very large online intermediaries and social 
media and e -commerce platforms that currently own approximately 10% of the market. He stated 
that the EU functions as a gatekeeper and therefore seeks to protect civil liberties – such as privacy – 
by employing its EU Data Protection (GDPR) legislation. Regulation of digital platforms is imperative, 
especially if we wish to continue nourishing a lively democratic society respecting social justice 
imperatives.  
Elaborating on the development of recom mendations on AI Ethics, Emma Ruttkamp -Bloem presented 
an overview of actionable and meaningful AI ethics policy. This policy is UNESCO ’s Recommendations 
for an Ethics of AI, as drafted by the UNESCO Ad hoc Expert Group on the Ethics of Artificial Intellig ence 
(AHEG). Not only do these recommendations include principles to guide the development, 
deployment and usage of AI, but they also promote inclusivity, fairness and diversity, especially by 
encouraging multicultural participation. This presentation was complemented by Golestan Radwan 
who also focused on the Recommendations. Ms Radwan presented a detailed overview of the values, 
principles and policy sections and how they align with UNESCO ’s central domains of work, such as the 
Education, Science, Culture  and Communication and Information sectors. She concluded that it is 
imperative to regard this document as a living document that will need to be reviewed regularly every 
few years.  
James Brusseau contemplated a decentralised and accelerated Artificial Int elligence Ethics. He 
problematised not only information for all, but also the nature and availability of information at all. 
He stated that the discourse should not just focus on the protection of data, but rather be concerned 
that the individual can be id entified by 'de -anonymization' of a conglomerate of data sets. Due to the 23 
 lag in AI ethics, regulations, policies and legislation, he argued that AI ethics must be decentralised 
and be made accessible to everyone across all phases of the lifecycle. AI ethi cs should not be in the 
purview of experts only, since it does not only impact experts. The development of AI ethics can 
therefore be accelerated if more people have access to it, thereby removing bottlenecks caused by 
regulators and experts.  
Towards addin g to the expanding literature on AI and assisting with ethical guidelines, Louise Pryor 
presented “A Guide for Ethical Data Science ”. Although this guide specifically pertains to the domain 
of actuarial sciences, its thematic recommendations apply to a var iety of sectors. Marjorie Ngwenya 
presented on ethical Artificial Intelligence and consumer protection and the role businesses can play 
in resolving issues caused by AI. She emphasised the responsibility of developers, governments and 
industry in ensuring that ethical considerations are part of parcel of the entire lifecycle of AI and its 
management. These sentiments were echoed by Danielle Davis who warned against the ethical and 
legal implications of AI particularly concerning marginalised societies. She argued that whilst AI can 
make data -driven decisions, it cannot replace human abilities such as judgement and values such as 
freedom.  
Positioning the role of media and information literacy in the AI and information accessibility 
deliberations, Prof.Felipe Chib ás Ortiz, referred to the evolution of smart cities into media and 
information literate cities. In these cities factors that enable literate citizens are promoted. Literate 
citizens can actively contribute to the Fourth Industrial Revolution and will t herefore not be excluded 
in the continuous development and integration of AI in our daily lives. He argued that we need 
multicultural, transdisciplinary and multi -stakeholder collaboration, policies, and solutions to 
concerns and gaps presented by emerging  technologies.  
Examples of such concerns include the malicious use of AI (MUAI), which was expanded on by 
Mohammed El -Guindy. MUAI was defined and elaborated on, indicating how governments, criminals 
and organisations can use it to increase their efforts, whether it is surveillance, criminal activities or 
the pursuit of profit. It was established that due to the subversive nature of MUAI, education on ethical 
considerations of ICTs and comprehension of how these technologies work will enable policymakers, 
researchers and even general society to better identify, and deal with MUAI.  
  
 
 24 
 7.2. Overview of presenters  
 Wendell Wallach  
 Ethics, Engineering and Oversight  [8]  
In his speech, Wendell Wallach explored the sheer ubiquity and speed at which new applications are 
deployed is disruptive to organisations, governments, and the socio -technical fabric in which our lives 
are embedded. He questioned whether we can navigate t he opportunities and challenges and whose 
values will shape this trajectory. He stated that there was some indication as to the latter, for the 
values of the technocratic elite focus on efficiency and capital accumulation and were only 
occasionally respect ful of the values of communities being disrupted and reshaped. The technology 
industry only moderately felt responsible to promote accessibility, transparency and equality across 
societies impacted by their technologies. He considered for example how the d igital economy had 
exploded and witnessed tremendous growth during the Covid -19 pandemic. Poverty had increased 
due to the decrease in wages, compared to the stock growth of these technology industries.  
While he emphasised that to reach the goals stipulate d in the Sustainable Development Goals by 2030, 
emerging technologies will play a central role, he also identified the trade -offs (i.e. automatization of 
industrial processes versus employment of workers). Due to these, numerous principles of AI were 
being  championed by the OECD, UNESCO, etc., to guide the development and deployment of AI. 
Unfortunately, AI Ethics and AI for Good provided weak tools in comparison with the momentum of 
technology development. Another step towards sustainability was to focus o n the operationalizing of 
AI principles (see for example the IEEE ’s standard -setting). This step could be seen as soft law, as 
compared with hard law as implemented by the government. The former though is much harder to 
enforce, but it can benefit from eff ective governance by all countries who are interested to reap the 
benefits of these emerging technologies. He noted, once again, the unfortunate misalignment 
between the speed of technology development versus the slow pace of creating and implementing 
ethics guidelines and legislation. This encompasses the fact that the trajectory of the digital revolution 
is drawn towards surveillance capitalism, the weaponization of digital tools, and the inability to 
recognise opportunities for international cooperation.  An unfair situation arises allowing technology 
companies to reap the benefits of the technologies they deploy, without taking responsibility for the 
societal costs. The G20 recently endorsed the minimum 15% tax to be applied to these industries.  
Mr Wallac h ended his presentation on the note that policies and new approaches by governments – 
for being flexible and adaptive – were imperative! Towards contributing to this, an Inequality Initiative 
had been established at the Carnegie Council for Ethics and Inte rnational Affairs, due to the concerns 
that AI exacerbates structural inequalities, creates new forms of inequity, and negatively impacts 25 
 society. He established that value reset, soft law and well -designed policies and government reforms, 
could nudge the technology trajectory onto a sustainable path.  
 
Arthur Bezerra  
Artificial Intelligence, class, gender and race  [9]  
Arthur Bezerra began his presentation by stating that any discussion on AI policy and ethics, is 
intricately connected to the legal, cultural and technological questions, which are all embedded in the 
political economy of our societies. Information accessibility is closely related to educational 
accessibility. Conversely, in capitalist societies, education costs money. He held that when we are 
talking about policies related to AI practices that are more inclusive, we have to consider the 
conditions that make information accessibility more exclusive. Although AI technologies provide 
advantages, it also deepens inequalities and forms of oppression of groups that are the most 
vulnerable in societies. For example, the zero -rated practice is an example of a direct link between 
information access and economic power. This can be very concerning, for if one has access – at no 
data cost – to some social me dia platforms that are part of the business agreement, however, if one 
has no or restricted access to the general internet, then they cannot check whether the information 
they receive on the social media platform is accurate or fake.  
Hence, fact -checking becomes a privilege, available only to those who can pay to have access to 
information. Mr Bezerra mentioned examples of racial bias and facial recognition, together with the 
dystopia illustrated in the movie Minority Report . Other examples of information invisibility based on 
race, gender, class, employment opportunities, cultural events and the recommendation of romantic 
partners in dating applications were also given. According to his presentation, the big technology 
companies – who profit from these tec hnologies - do not seem to take any responsibility either for 
the implications on mental health and wellbeing or the addiction that accompanies the constant usage 
of devices and applications. Shockingly, this addiction is encouraged by companies to improve  usage. 
Therefore, information accessibility mutates into a form of information dependence where everyone 
feels the need to be constantly updated.  
In light of this, Arthur Bezerra highlighted the recent initiative (2020) taken by the Chinese 
Government to create the first set of standards for the regulation of the use of algorithms in the world. 
The key purpose of this was to ensure that algorithms follow principles such as ethics, fairness, 
openness, and transparency and also because special care is expect ed in the creation of users ’ 
classification models together with the endeavour to avoid using harmful and discriminatory 26 
 information. Additionally, this initiative was taken so companies avoid promoting compulsion or 
addition in the use of these services. Similarly, in Brazil, one can find an example of collaboration 
between government and civil society for the elaboration and implementation of a set of information 
policies aimed at digital technology. This was built around three pillars: 1) users ’ privacy,  2) net 
neutrality and 3) the non -input ability of companies that own digital platforms.  
Thus, the strengthening of collaborative ties between governments, companies, and civil society, is 
even more important in the search for a more inclusive and less opp ressive technological structure.  
 
Yves Poullet  
Do we need regulation of the digital platforms? An EU approach  [10]  
This contribution focused specifically on very large online intermediaries and social media and e -
commerce platforms. and that these companies  combined own 10% of the market. Yves Poullet 
pointed out that the EU functions as a gatekeeper between the technology companies, businesses and 
consumers – serving as a bottleneck – for important digital services. He argued it to be a justified 
opinion fo r a regulatory initiative from the EU public authorities, the reason being that the ubiquity of 
the presence of the technologies in our daily lives and different activities leads to an unprecedented 
collection of vast collection of personal data, significa ntly impacting our liberties. However, this is not 
the only risk. Other risks include:  
• The risk to collectivities, for example, profiling people  
• Threats to societal interests  
• Treats to the environment, for example, abusive conceptions of energy  
• Threats to democracy, for example, the recent Cambridge Analytica case  
• Systemic risks, for example, the shifting of public opinion and online trade. The companies 
must theref ore consider the potential misuse by the recipient and take appropriate action to 
mitigate concerns.  
In the absence of effective regulation and enforcement, EU authorities can set the rules, raising the 
notion of the platforms ’ social responsibility and as serting their obligation to assess their system. He 
guided how to regulate these platforms by looking into an EU disinformation case with specific 
reference made to the GDPR. Mr Poullet referred to two options - self-regulation and co -regulation. 
He also sh ed light on the EU Commission's Guidance to Strengthen the Code of Practice on 27 
 Disinformation in which the Commission noted that a new stronger code is necessary to regulate the 
companies making money from disinformation, whilst also fully preserving the f reedom of speech.  
Following this, he introduced a Draft regulation on Competition - known as the Digital Markets Act, 
2020. He stated that it was issued by the EU keeping in mind that the concentration of revenue and 
economic power can be as dangerous as th e concentration of political power, leading to social unrest. 
The DMA 2020 was issued to mitigate this because there was a need for a better -founded taxation 
model, a need to have interoperability and international standardisation measures and a need to 
apply competition rules which take the transversal value of information into account.  
He also stated that according to DMA, a gatekeeper must operate a Core Platform Service. CPS 
consisted of essential services in our digital world offered by very large pla tforms and included search 
engines services, social media networking services and information platforms, cloud computing 
services etc. The regulation should be available only for gatekeepers through asymmetric legislation 
with three criteria to define thes e gatekeepers: 1) they must have a significant impact on the market, 
2) they must play a gateway role between business and individuals  3) they must have an entrenched 
and durable position. This regulation must be founded on legitimate reasons, such as the  fight against 
disinformation, profiling, and anti -competitive or discriminatory practices. In conclusion, regulation 
for digital platforms is needed if we want to keep a lively democratic society respecting social justice 
imperatives.  
 
Emma Ruttkamp -Bloem  
Actionable meaningful AI ethics policy  [11]  
                        Through her presentation, Prof. Emma Ruttkamp -Bloem reflected on the UNESCO Ad 
hoc Expert Group on the Ethics of Artificial Intelligence (AHEG), which includes broad and global 
stakeholder  consultations. She submitted that the revised version had been submitted for finalisation 
during May/June 2021, with a possible adoption during the UNESCO General Conference in November 
2021. The most important consideration was for it to be considered as  a recommendation for a global 
instrument on the ethics of AI. Its focus areas include gender equality as well as the protection of the 
environment and ecosystem.  
                        Next, Prof. Bloem highlighted the challenges that have arisen in the  process of achieving 
a global instrument. Two specific challenges have been highlighted:  
1. Reality does not necessarily reflect the goals, values and principles mentioned the draft;  28 
 2. The exclusion of low -and middle -income countries from most international di scussions on AI 
and AI ethics has different implications  
She held that considerations then not only include representation of a diversity of values and ethics 
in AI, but also the adherence to policies, should regulations be implemented. An extremely import ant 
point to be considered and integrated is the recognition of diversity in value representation to ensure 
inclusivity in the final recommendations.  
It was noted that the AHEG followed some basic rules to guide its research, consultations and ultimate 
guidelines. AHEG focused on internationally agreed mechanisms, such as the Sustainable 
Development Goals. Moreover, it focused on human and environmental concerns that essentially 
emphasise the urgency of the implications of AI. Various values and principles  have been included in 
the draft recommendations, and there has been a commitment to find the middle -ground between 
the diverse collection of values and principles[12].  
She pointed out that of core importance is the possibility of actionability, and this has been attended 
to by different policy areas and instruments for monitoring and evaluation.  
Prof. Ruttkamp -Bloem also addressed the major area of concern when speaking of AI and that is the 
Nature of Ethics. Together with this, accountability, diversity of vulner able groups, education, bias, 
exploitation and inequity, and ecological concerns were also raised.  
 
James Brusseau  
Artificial Intelligence Ethics decentralised and accelerated  [13]  
James Brusseau opened his presentation with the statement that it is essen tial to not only consider 
“Information for All ”, but also information at all . This is specifically of relevance in the discourses 
about AI and the human condition, as it is difficult to get a real sense of what is happening in this space 
of interaction. He  provided us with an example of a hospital in Italy during the Covid -19 pandemic, 
where they would be overwhelmed by a large number of patients but not enough radiologists to 
analyse their chest x -rays, thus assisting with a diagnosis. To mitigate this, th e idea was proposed to 
develop AI to assist with these analyses, however, there was a lack of training data to make this work, 
which specifically entails the usage of patients ’ health data. Therefore, in the consideration of strictly 
adhering to privacy co nsiderations, some of these “restrictions ” had to be loosened to allow access to 
the information for the training of AI and to further serve a greater social purpose. Mr Brusseau held 
that it is an arduous task that takes very long, but AI and emerging tec hnologies are sprawling across 29 
 all aspects of our personal and professional lives. Owing to this very reason, our traditional ways of 
doing AI Ethics and considering our human condition concerning technology simply cannot keep up.  
He suggested that a solut ion to this is to propose decentralising AI Ethics - an attempt to create ethics 
knowledge on a vast scale and rapidly, to make humanist information available and accessible to 
everyone everywhere. There are three steps to this goal:  
• The source of th e information – decentralised versus centralised – means that AI ethics no 
longer start with experts, but instead with common public information;  
• Evaluation – with decentralised AI ethics, this step starts with machine learning and natural 
language processing and not necessarily with experts. Here the vast amount of available 
information can be analysed with metrics that are universally accepted amongst personal (i.e. 
autonomy, privacy), social (i.e. fairness, social well -being), and technological pr inciples (i.e. 
performance, accountability).  
• Implementation - The complexity of academic research and consultation together with the 
processes of publishing findings and recommendations, then engaging with expert groups 
(governments and agencies) to develop and implement regulations and laws, causes a lot of 
delays. With decentralised AI ethics, the implementation will be in real -time. This will entail 
getting a large amount of ethical data out to the public, which is a critical element to solve the 
problem of AI ethics that is too slow and behind.  
In conclusion, current methods for evaluating the human benefits and risks of AI cannot keep pace 
with the technology's dissemination. Decentralised AI Ethics proposes to solve the problem using AI 
to apply AI ethics to AI intensive companies.  
 
Louise Pryor  
Ethical Data Science  [14]  
Louise Pryor opened her speech by describing Actuaries as problem solvers and strategic thinkers who 
use their mathematical skills to help measure the probability and risk of futur e events. She noted that 
actuaries – who not only work in the financial sector but other industries – had been working with 
large amounts of data since the 18th Century. Actuaries are keenly aware of the ethical dimensions of 
their work, big data and AI, a nd how these for example impact notions of privacy. Due to the rapid 
growth of these emerging technologies, actuaries need to keep up to date with the growing and 
challenging ethical issues.  30 
 She identified that the public ’s interest must be upheld and to achieve this, the Royal Statistical Society 
(RSS) and the Institute and Faculty of Industries (IFOA), have collaborated to compile “A Guide for 
Ethical Data Science ” [15]. Five key themes are i dentified in this guide:  
• Seeking to enhance the value of data science for society  
• Avoiding harm  
• Applying and maintaining professional competence  
• Seeking to preserve and/or increase trustworthiness  
• Maintaining accountability and oversight  
Her speech settled that these themes could not be seen in isolation from each other. She provided 
examples provided of how AI and big data – and emer ging technologies – could go wrong. Together 
with these issues, such as bias based on race and gender, solutions were provided. On a concluding 
note, she stated that good governance and ethical oversight will help address these issues and that 
both the imp lications and the source of these concerns need to be managed ethically. Therefore, the 
designers of automated systems must consider what the impact of their decisions will be on society 
and the environment. There was immense scope in applying the guide, w hich was complemented by 
the recognition that we must consider the whole picture offered by AI, including its benefits and 
challenges.  
 
Marjorie Ngwenya  
Ethical Artificial Intelligence and Consumer Protection  [16]  
Marjorie Ngwenya's presentation specificall y focused on the role businesses can play in resolving the 
issues presented by AI. She referred to a study by the Ottawa Citizen which illustrates the amount of 
data that has been collected on Canadians by Meta, Google and Twitter. Based on the results of one 
person who willingly participated, the amount of data that was downloaded by this individual came 
to roughly 1.66 gigabytes (compare this to the average Kindle ebook which is 2.6 megabytes!). 
Combining the amount of data available with AI, the scale wa s compounded.  
  
In her presentation, Ms Ngwenya reflected upon the importance of the Ethical application of AI for 
consumer protection. Notwithstanding the numerous existing regulations and guidelines on the ethics 
of AI, what exactly constitutes the ethic al application of AI and which standards must be met? Three 31 
 options include transparency, equity, and privacy. Each of these ethical considerations was expanded 
on together with examples.  
 She stated that responsibility in an AI context concerns how the k ey issues and challenges of AI can 
be managed, particularly about consumer protection. Five ways in which consumer -facing 
organisations can move the agenda forward were recommended:  
1.     Create internal frameworks that outline a company ’s data stewardshi p 
2.     Data and model transparency requires attention  
3.     Education is required for all stakeholders  
4.     Dedicated risk management and investment are required due to the rapid development of AI  
5.     Independent and third -party reviews of a compan y’s practices must take place  
In conclusion, AI brings with it several complexities, but together with this it also provides 
opportunities for businesses to engage with it in a socially responsible and inclusive manner. The 
multi -Stakeholder collaboration will be at the core of the way forward.  
 
Danielle A. Davis  
AI, decision -making and the role of human judgment  
This presentation considered AI and its role in society, as well as the ethical and legal implications on 
marginalised communities. Danielle A. Dav is held that though AI is applied ubiquitously in our modern 
society, AI intelligence is not inherently more accurate, fairer, or less biased than humans. Therefore, 
how we treat artificial intelligence needs to account for this reality. This is particular ly true when the 
data that is being used mirrors existing social inequalities. Reimagining diversity and inclusion efforts 
could help mitigate the current biases we are seeing today such as not to further entrenching the 
divides and exclusions experienced by marginalised and vulnerable societies.  
In her speech, Ms Davis identified that in terms of ethical concerns, there are three buckets in which 
these can be categorised. They are 1) the privacy and surveillance bucket, 2) the bias and 
discrimination bucke t, and 3) the role of human judgement. Each of these contain their complexities 
and consequences. However, an umbrella question arises which should be prioritised: “Can smart 
machines outthink us ”? Or, are there human elements that cannot be replaced by AI  and are 
indispensable to our daily engagements, such as liberty? The latter point is argued to be essential. 32 
 However, we must ensure that it does not negatively impact our rights such as freedom of expression, 
nor promote bias.  
Conversely, it must be ackn owledged that AI does have its advantages because it assists with decision -
making. The more society – consisting of both individuals and organisations – is informed of both the 
challenges and benefits, the better they will understand the ethical and legal implications. Inclusivity 
and diversity should be incorporated from the onset of any AI -related project to ensure bias is 
mitigated.  
 
Golestan Radwan  
Egypt Artificial Intelligence Strategy  [17]  
The presentation by Golestan Radwan highlighted the relevant as pects of the UNESCO Ad Hoc Expert 
Group (AHEG) on Ethics of AI ’s recommendations, insofar as it pertains to the topic of Artificial 
Intelligence for Information Accessibility. An overview of the draft recommendation document was 
provided, which is also ava ilable for download  [18]. In the preamble, the context is situated whereby 
it primarily covers the broader ethical implications of AI in UNESCO ’s central domains of work 
(Education, Science, Culture and Communication and Information sectors).  
It was discuss ed that when access to information is considered, several elements come to mind, such 
as transparency, journalism, social media, privacy, freedom of expression, mis - and disinformation, 
media and information literacy, ethics, etc. However, there is an even  wider perspective that comes 
to mind when we consider access to information, namely, the right to know or the right to be informed 
across all other domains of application. An example includes healthcare, which also contains the 
implementation and usage of  AI and automated systems. This extends to not only health practitioners, 
but also the designers of the technologies, insurance companies and patients. Especially when looking 
at the last example, at what point is it acceptable or unacceptable, to inform a  patient of a certain 
prognosis based on probabilities because of AI, especially if there is a likelihood of error? How is this 
information communicated, and how will the patient understand how the system works that provided 
this information? It is therefo re evident that the concerns do not just extend to information, but also 
to explainability of AI systems, technical limitations, and advances in the systems, as well as legal and 
liability issues. She noted that all of these are covered in the draft recomm endations.  
Ms Radwan drew attention to another broader dimension that arises when looking at AI ethics and 
access to information. This is access to AI knowledge itself, which is mostly confined to high technology 
industries in developed countries. Unfortunately, due to the proliferation of AI in our lives across all 33 
 sectors, it also influences marginalised and underrepresented groups. The digital divide is therefore 
not only maintained but it is also amplified. Based on the foregoing, the draft recommendations 
emphasi se human rights. She stated, however, that the notions of additional human rights – such as 
the right to know in terms of AI systems – are not something that can easily be added to, since it must 
adhere to the Universal Declaration of Human Rights and be f ormally included in the declaration. It 
may be a good argument in itself, but it does delay progress and inclusion of these ‘emerging ’ human 
rights as the technologies continue to advance.  
Although values and principles are contained in the draft recommend ations, another section is 
dedicated to policy actions that pertain to the Communication and Information Sector of UNESCO. 
This section focuses on bridging the digital divide and improving access to information, and also how 
AI should achieve these require ments.  
 She concluded that it is evident that information access is present in nearly all sections of the 
recommendations on the ethics of AI. It is imperative to regard this document as a living document 
that will need to be reviewed regularly every few years.  
 
Felipe Chib ás Ortiz  
Artificial Intelligence, Policy and Ethics: Free related issue in post -human society  [19]  
Prof. Felipe Chib ás Ortiz, in his presentation, asked, what do people understand by AI, ethics, and 
public policy? He further explored the multiple relationships between these three elements which 
have also been discussed in detail in the book “From Smart Cities to MIL Cities ”, containing metrics 
inspired by the vision of UNESCO ” [20], edited by him and Mitsuru Yanaze  [21].  
He discussed that du e to the advances in technologies in the field of AI, compounded by the Fourth 
Industrial Revolution, all sectors of society have been impacted. This impact called upon the need to 
evaluate existing policies, strategies and ethics guidelines not merely to mitigate the risks these 
technologies pose, but also to guide best practices. He also questioned whether the cities we call 
'smart cities' prioritise ethics in their development? The need for governments to collaborate with 
specialists and researchers in t he field, to ensure the policies encapsulate ethical principles, and to 
further guide projects, programmes and activities, was discussed in this presentation. Examples 
included the lack of policies promoting transparency of the design and development of AI  technologies 
in telecommunication and tech giant industries; the identification of discrimination based on gender, 
religion and race, as well as the occurrences of fake news, hate speech and restrictions in freedom of 
expression.  34 
 Prof.  Chib ás Ortiz suggested Mini stries, or Departments, of Justice, prioritise regulation and 
legislation, with clear guidelines for responsible and legal behaviour, with consequences and 
punishment stipulated if contravened. He concluded that despite living in a ‘post -human’ world, we 
believe that technology can solve any problem humans may have and this is the greatest mistake we 
can make. We need multicultural, transdisciplinary and multi -stakeholder collaboration, policies, and 
solutions.  
 
Mohammed El -Guindy  
Malicious use of Artificial  Intelligence  [22]  
The presentation aimed to shed some light on the malicious use of AI (MUAI) and the implications on 
national security. The legendary Alan Turing (195) had asked the question “Can Machines Think? ” 
Mohammed El -Guindy stated that the answer  to this was far from simple and therefore required a 
philosophical debate. He said that intelligence is a controversial topical, especially insofar it pertains 
to man -made machines. Classification also becomes both complex and necessary, which is why 
spec ialists classify it as weak, or narrow AI, strong or general AI, super AI, or self -aware AI. Sure, AI has 
contributed to the distribution of the world, but it can also be used in a beneficial manner, i.e in 
strengthening national security.  
Reference was ma de to the Capacity Building Programme of the United Nations Office on Drugs and 
Crime  [23], which uses crime analysis and prediction tools for investigation purposes. Think for 
example of facial recognition to identify human traffickers and terrorists. Howe ver, every coin has a 
different side. Whilst AI can prevent crime, AI can also be used by criminals to increase their activities 
and efficiency. Mr El -Guindy discussed the book by Pedro Dominquez “The Master Algorithm: How 
the quest for the ultimate learni ng machine will remake our world ” which discusses the ability of 
criminals to become supercriminals! He pointed out that AI can be used in three malicious ways: 1) 
cybersecurity, 2) physical security and 3) political security (computational propaganda). Ea ch of these 
instances was elaborated on during the presentation.  
Two important initiatives that contribute to addressing the concerns together with providing potential 
solutions were also emphasised, during this presentation. These initiatives were:  
• The UNESCO AI Initiatives  [24] 
• The IEEE Ethically Aligned Design  [25] 35 
  
Furthermore, Mr Mohammed made specific recommendations:  
• Universities should implement Information Ethics, AI Ethics, Law and Cybersecurity in their 
curricula  
• Policymakers and r esearchers must understand the malicious use of AI  
• Regulation and best practices should be addressed with dual -use technologies such as AI  
 
He closed his presentation with a quote from Norbert Wiener which states that “The world of the 
future will be an e ver more demanding struggle against the limitations of our intelligence, not a 
comfortable hammock in which we can lie down to be waited upon by our robot slaves ”. 
 
References  
[6] https://www.youtube.com/playlist?list=PLTULETeBko5GUuVnfR0azmdQ8mGoS6r9Q  
[7] https://www.youtube.com/playlist?list=PLTULETeBko5GUuVnfR0azmdQ8mGoS6r9Q  
[8] https://youtu.be/AHPFU5VwRto  
[9] https://youtu.be/MMlS3AkpQBw  
[10] https://youtu.be/IZ9FeBqOLq8  
[11] https://youtu.be/ILxUpoAhkHc  
[12] https://en.unesco.org/artificial -intelli gence/ethics  
[13] https://youtu.be/Sl6yBGuuSGg  
[14] https://youtu.be/HHucb3OcXKk  
[15] https://www.actuaries.org.uk/upholding -standards/data -science -ethics  
[16] https://youtu.be/LVoeeb7UZwc  
[17] https://youtu.be/TUieQkV_9Xc  
[18] https://en.unesco.org/artificial -intelligence/ethics#recommendation  
[19] https://youtu.be/PNzVkUDXRV4  36 
 [20] https://en.unesco.org/milcities  
[21] 
https://www.academia.edu/43369259/FROM_SMART_CITIES_TO_MIL_CITIES_Metrics_inspired_by_
the_vision_of_UNESCO  
[22] https://youtu.be/mZ4 -BwAq2c8  
[23] https://www.unodc.org/unodc/en/data -and-analysis/capacity -building.html  
[24] https://en.unesco.org/artificial -intelligence  
[25] https://ethicsinaction.ieee.org/  37 
 8. AI and Society  
 
8.1. Introduction  
This thematic area had thi rteen presentations that explored notions of law, multi -stakeholder and 
multisectoral responsibilities, the features of future AI societies and recommendations for bridging 
divides. The global representation was excellent, with presenters from Jamaica, Mex ico, the United 
States of America, Canada, Germany, and Uganda.  
Prof.Verene Shepherd discussed the 'computer must have gotten it wrong ’ and the various excuses 
that are made to (silently) condone bias and prejudice. She stated that this excuse has been use d for 
the misuse, and oftentimes abuse, of AI. These instances are observable especially within law 
enforcement agencies, extending to predictive policing based on facial recognition, data harvesting 
and data surveillance, all of which contribute to the pr ofiling of citizens. She noted that with any 
advancement, there are related opportunities and risks. However, for this very reason, media must 
play a critical role in society. Since mass media can mitigate some of these concerns, they must be 
used effectiv ely as a tool for advocacy, education, and public awareness.  
 The question Can transparency restore accountability was posed by Vijay Chauthaiwale and the 
presentation opened with the oft -quoted statement “with great power comes great responsibility ”. It 
was discussed that this responsibility is very much on the shoulders of developers, who must ensure 
due consideration is given to the design of algorithms and autonomous systems. One of these 
38 
 concerns pertains to how the algorithms work, which leads to the  notion of the uninterpretable “black 
box”. A call was made for transparent AI and the governance of organisations that develop, design 
and implement AI.  
Inaccessibility of data, especially if it concerns the local communities from when it was originally 
collected without them owning the data, is what is meant by the term colonised data. Nithya 
Ramanathan problematised such colonisation and called for the decolonizing of data. This can be 
achieved by advocating for countries to own their data, ensuring coun tries are involved in the 
decision -making about their data and promoting standards such as interoperability.  
Following data colonisation, Scott L David presented on the rise and demise of computational 
sovereigns and the emergence of verified information c ommunity environments. He compared the 
extraction of electronic resources to the historic e xtraction of resources in a colonial setting, even if 
there was consent . Currently, if you control the data, you control the data. He argued that we need to 
consider  the meaning of concepts and values, such as the inherent differences between access and 
accessibility. If you do not get the meaning of information, even if you have access, it will not be useful 
to you. In essence, equity remains a big focus when discuss ing the actual aim of ethics insofar as it is 
applied to AI and emerging technologies. Although it is noted that ethics should not be conflated with 
legislation, it is worthwhile considering how equity can be promoted across societies. Community is 
the mos t authoritative source of where identity comes from. Perhaps then one day, after the 
computational sovereigns, humans will come back and explore the notion of the “human” community 
again and the knowns and unknowns of what it means to be human. In this ins tance, it is possible to 
consider that AI is giving us a common challenge to ask, “Whom do we want to be ”? This is a great 
question to ask a human species.  
Seynabou Ndiaye explored how AI can be a tool to bridge equality gaps whilst acknowledging that it 
has certainly contributed to the creation of gaps. She provided examples of AI ’s contribution to 
improving literacy, providing access to applications about healthcare information, agricultural 
practices, resource allocation and consumption, as well as the s treamlining and delivery of essential 
services. Notwithstanding the models and technologies that achieve social good, concerns are 
compounded by a lack of regulation, monitoring and evaluation. Therefore, it is essential that the 
public must be informed of  AI, its implications and how it works; policymakers must also understand 
how AI works to better respond to the rising challenges, and standards should be created to improve 
transparency.  
Sheila Beladinejad provided a feminist perspective on Women in Artif icial Intelligence and Robotics. 
She unpacked how digital transformation and AI relate to access to information, the effects of gender 39 
 disparity in AI, and finally, she provided recommendations on what can be done to address these 
issues. Characteristics t hat contribute to such gender (and even racial, religious and ethnic) disparities, 
include the type of data available, the quality and accuracy of data, as well as the explainability of 
algorithms and how it interprets this data. On the other hand, due to the digital transformation, more 
women should be able to access economic and education opportunities, which leads to the 
empowerment of women.  
The issue of knowledge representation and inclusion was raised by Adriana Labardini when unpacking 
cognitive just ice. She explained what is meant by this type of justice and linked it to indigenous 
knowledge and the promotion of co -existence between all forms of knowledge. She argued that AI, 
and society, need to acknowledge and include knowledge and value pluralism to allow for diversity 
and inclusive design of emerging technologies. Towards promoting opportunities for small businesses 
and new market entries by entrepreneurs, Diana Paredes showcased the platform Suade , which is a 
tool – utilising AI – that assists wi th increasing the capacity of bankers to have better access to 
information. By employing Agile Regulation Technology, stable and well -informed financial services 
can contribute to stable societies. Financial technologies, and the regulation of these techno logies, 
assist with agile governance because it not merely promotes responsibility for profit, but it also seeks 
to improve digital infrastructure and services.  
 A very informative and technical presentation on algorithmic effectiveness was given by Chuck  
Howell. He discussed how Sociotechnical Systems (STS) will enable the right to know and improve 
mitigation efforts to reduce harm in an autonomous system. On the concept “Left of the algorithm ”, 
he explained that it implies that checks and balances need t o occur before the action takes place. He 
indicated that participatory design is essential in the early design phases of algorithms. Such an 
inclusive approach helps in understanding how AI systems affect, and are affected by, social 
constructs, assumption s, and individual and collective behaviour.  
 Hero Laird ’s presentation on Ethics, Artificial Intelligence and the Law: A truth about stories , made 
the argument that if technology can affect law, then it means the law can affect technologies. How do 
stories fit in? Ms Laird explained that we co -evolve with technologies, law, and other constructs in 
society, These constructs influence the narrat ives we use and apply to current contexts and shape our 
interaction with one another and AI. We need to ensure that as humans, we continue to shape society 
and know what it means to be human, without letting AI shape/define this for us. The role of the 
society was echoed by Susan Juliet Agwang who represented a pan -African civil society organisation. 
She held it crucial for us to utilise tools – such as AI – and align our actions towards achieving the 40 
 Sustainable Development Goals (SDGs) as well as towards the observance of Article 19 of the Universal 
Declaration of Human Rights (UDHR).  
Claire Nelson took us on a journey of future decision -making, tools, industries, education, and elderly 
care as found in the age of AI. Her journey extended beyond the SDG go als of 2030, into 2050 and 
beyond. Elaborating on the vast array of these services, she said that although these opportunities 
sound exciting, we must be ready to meet this future by getting smart and being equipped with the 
right attitude and abilities. H ow do we cultivate these attitudes and abilities? Jason Lewis presented 
Future Imaginaries through indigenous Artificial Intelligence , by basing it on his culture and how it is 
imagined – visualised, enacted and presented – in an AI -informed society made a ccessible in one ’s 
mother tongue.  
 
8.2. Overview of presenters  
Verene Shepherd  
The computer must have gotten it wrong: Artificial Intelligence and Racial Profiling  [27]  
The presentation intended to identify how the excuse “the computer must have gotten it wrong ”, has 
been used to misuse AI. Even law enforcement is guilty of this misuse, and hence the media must 
remain vigilant. Our global communities have been propelled into a new phase of development due 
to the advances in technologies and the establishment of global social media platforms. However, one 
should not forget that the same platforms and the application of AI advance our global citizenship, 
and also differentiate us – and collect our data - based on our gender, race, religion, cultural 
backgrounds, et c. Prof. Shepherd stated that our identity is “as unique as our fingerprints ”. 
She went ahead to consider the scope and depth of access to data that law enforcement agencies 
have on citizens, including images and personal information. This data is not only  gathered from social 
media platforms but also from government databases, financial and health records and surveillance 
technologies. Moreover, with increased pressure by forms of terrorism and migration of refugees and 
asylum seekers, the use of AI decisi on-making tools, may inadvertently contribute to increased racial 
profiling against ethnic minorities. Stereotypically, black, and brown communities are targeted due to 
racial profiling. She discussed that with these tools, the possibility of algorithmic b ias will always occur 
when used in a law enforcement context. Reference is made to the Committee on the Elimination of 
Racial Discrimination (CERD) General Recommendation 36[28], adopted in 2020. This 
recommendation seeks to address the growing internation al human rights concerns regarding the use 
of facial recognition software in law enforcement.  41 
 With any advancement, there are related opportunities and risks. However, she called upon the media 
to play a critical role in society. She insisted that the media must provide information to the public on 
the related policies and legislation so the public  is well -informed of their rights. Mass media is a tool 
that allows for all forms of leadership to remain accountable to its citizens and in the digital society, 
the media plays an even greater role! Therefore, the costs and benefits to society of these em erging 
technologies must be calculated. It must also be ensured within policies, regulations, and legislation, 
that these technologies are designed and used objectively, efficiently and devoid of prejudice and 
abuse. It is the role of the media to keep lea ders honest, promote advocacy, and keep the public aware 
of the implication of these technologies on their human rights.  
Through her presentation, Ms Shepherd conveyed that in the absence of public awareness of human 
rights – and potential abuses such as r acial profiling – the ability of citizens to question abuses and 
demand reprieve, is threatened. Hence, the media bears two burdens: 1) they have the responsibility 
of informing the public of instances where state actors have impeded human rights, and 2) t hey have 
the responsibility to promote international human rights conventions and support the advocacy of 
human rights defenders.  
In conclusion, it is up to us – as global citizens – to correct the faults in the programming of AI tools 
towards ensuring tha t everyone can enjoy their freedoms, rights and security in peace.  
 
Vijay Chauthaiwale  
Can transparency restore accountability  [29]  
Vijay Chauthaiwale opened his presentation with the quote: “With great power comes great 
responsibility ”. This is especially true about AI which is already part of our personal and professional 
lives and integrated across public and private sectors. Accountability is a very important component 
in any AI policy, it means there is someone responsible for the AI design, implementat ion and 
responses. There is still a question concerning how the algorithms work, which has led to the notion 
of the uninterpretable “black box ”, or the accountability gap.  
In his presentation, Mr Chauthaiwale emphasised how the human workforce is being rep laced by an 
autonomous workforce but also questioned how this latter workforce be held responsible should 
something go wrong. How will one be able to explain the AI ’s decision -making? This black box concern 
has led to numerous initiatives that address the need for explainability and transparency of AI, for 
example, the GDPR ’s “right to explanation ”. Promoting algorithmic accountability is the primary 
contributor to explainability, for it also encourages access to information. Explainability also requires 42 
 a provision of how certain parameters are utilised in the design of an algorithmic system, for the 
concept in itself does not ascertain those inferences made are wholly accurate. This might be due to 
flawed data that has been input into the system, which wil l lead to flawed results and/or decisions. 
An explanation is therefore not exactly equivalent to transparency. This leads to the inclusion of the 
principle of fairness which is closely connected to transparency. And subsequently, fairness leads to 
legal co nsiderations such as liability should an AI system be opaque or make wrong, inaccurate, or 
false decisions.  
In conclusion, he said that the call for a transparent AI system is justified whilst accountability 
promotes answerability. Achieving this will not be an easy task; hence governance, multistakeholder -
collaboration and management of AI systems need to take place throughout the entire lifecycle.  
 
Nithya Ramanathan  
Decolonizing Data  [30]  
A footnote to the presentation is made that it contains excerpts f rom the Skoll Forum 2021 
conversation “Decolonizing Data ” [31] : 
Data is increasingly at the core of the social impact sector. However, there is a pernicious pattern of 
data colonialism in today ’s commercial tech ecosystem. As social entrepreneurs, we are c ommitted to 
shifting power to the communities we serve and need to actively fight the forces of data colonialism. 
Join this fireside chat for a deep dive into data colonialism and a discussion of methods to resist —and 
reverse—it. 
In her presentation, Nithy a Ramanathan answered what “Decolonizing Data ” means and how it relates 
to “data colonialism ”. She defined the latter concept as when one entity claims ownership of data that 
is produced by others or for others. A disturbing trend is arising whereby organi sations – albeit with 
bonafide intentions – go to a country or region and collect data from others (such as health data) and 
keep this data to be utilised for analyses. They in essence derive value from this data, at the expense 
of the originators, such as  local communities. In extreme cases, some of the data is taken without 
consent and even published privately without being made public. This loses the context of the local 
communities and/or countries from where the data has been taken and is utilised for decision -making 
without the knowledge of the originators.  
Consequently, the following question arises: “How does data colonialism reinforce traditional 
colonialist thinking and structures ”? Ms Ramanathan considered as examples the removal of 43 
 resources with out consent, the formal systems in place that enable this extraction, and the rhetoric 
of how this is contributing to progressive research and monitoring and evaluation processes. And 
finally, similar to the extraction of primary resources that are extract ed from one country but refined 
in another country, the same pertains to the extraction of data from one country but analysed and 
used in another.  
Hence, emphasis was placed on the fact that, data is knowledge, is power, and is money and that each 
of these  steps is value -laden and ultimately leads to economic gain by the ‘data colonialist ’. She stated 
that understanding the fundamentals of disrupting data colonialism will assist with finding restitution. 
These include: 1) countries should own their data 2) they should make the decisions about the data 
and 3) contain standards such as interoperability.  
Moreover, she took the example of Nexleaf  [32] as one of the organisations that partner with 
countries to ensure they have the data they need to build lasting s olutions that improve the health of 
people. Unfortunately, good intentions are not enough, and therefore one must remain vigilant that 
data is not taken away from the local communities without the knowledge. To support this vigilance, 
it helps to recognise  data colonialism and aspects that are related to it, such as 1) data ownership and 
data accessibility, 2) benefits of data and data beneficiaries, 3) discerning how the decisions are made 
and 4) the issuing of a set of data rights  [33]. As an organisation,  Nexleaf seeks to incentivise high -
quality data and high -quality data use by providing steps to achieve these foregoing considerations.  
Ms Ramanathan concluded that decolonising data has emerged from indigenous groups concerning 
their data rights and other  organisations dealing in this space. Even though this is an emerging topic, 
the definitions and concepts are being broadened into different sectors. Thus, we must understand 
that owners of data own power and by returning data to its actual owners, the dat a asymmetries can 
be addressed, and data decolonised.  
 
Scott L David  
Synthetic Human Intelligence (SHI) in human history  [34]  
The presentation looked into the rise and demise of computational sovereigns and the emergence of 
verified information community en vironments. The context was sketched of how humans adapt to a 
changing (information) environment, with specific reference made to us being “homo sapiens sapiens 
sapiens” which translates into “those who know, that they know, that they know ”. Scott L David then 
argued that the power of the human species is not physical, but rather an information. Certainly, we 
are not as strong as certain animals.  44 
 Mr David dove into the concept of humans as sovereigns, whereby sovereignty entails being an entity 
that neither needs to ask permission nor forgiveness. He gave examples of such sovereigns nation -
states, corporations, property, etc.) and stated that due t o moving from physical beings to information 
beings, we also see the move from physical to information sovereigns, where the efficacy of our 
information development and utilisation of ICTS (including AI and other emerging technologies) 
constantly increases . The question, therefore, arises as to how do we manage these computational 
challenges, and how do the crypto -based systems manage us?  
He argued that there is a need for new sovereign stories to enable humans to shift from physical to 
information beings, which allows for a space to consider the implications of computational sovereigns, 
information goods and complexity. This is certainly a unique period in humanity ’s history, where the 
internet and ICTS have raised new information risks which did not exist before. Two main problems 
that are new and unique now are: 1) the blinded hierarchy power, where all human organisation is 
hierarchical which leads to centralised information flows, and 2) the “flood of interactions ” problem 
whereby there is an exponential ly increasing volume of interaction with ICTs. To counter these 
problems, Mr David recommended that communities of “self-interested ” parties de -risk together. He 
suggested that this might be achieved by having sustainable and resilient systems which are ba sed on 
notions of risk mitigation and leverage (governance by network effect), as well as elevating human 
cooperation, such as a network “neighbourhood watch ”. 
Currently, computational sovereigns offer only interim solutions which are generalised and based  on 
collected data and programmed algorithms and do not adequately address the unique and specific 
challenges experienced by humans. Since generality does not necessarily lead to equity, he suggested 
that post -computational sovereigns might therefore lead to the rise of community -based synthetic 
intelligent sovereignty, which will need to encompass consideration of scaling issues and promoting 
(or protecting) self -interest. He concluded by stating that the interoperability of global communities, 
and the man agement of intercultural paradox, will be the service that artificial intelligence and 
machine learning offer to humans on the continuing path to discovering and inventing who we – like 
humans – will be. This should lead to greater resilience of societies and greater participation within 
society.  
 
 
 
 45 
 Seynabou Ndiaye  
Artificial Intelligence, a tool to bridge equality gaps?  [35]  
AI has contributed to the widening of equality gaps in the past few years. However, despite concerns 
about AI’s impact on society, it ha s the pa powerful tool to bridge these gaps. The presentation by 
Seynabou Ndiaye focused on the various ways in which AI can resolve certain equality gaps and 
contribute toward creating a more accessible world (whether it improves health care or even bette r 
food systems).  
Some of these considerations include encouraging transparency, the implementation of ethical AI and 
the adoption of standards and policymaking about AI. Ms Ndiaye also discussed how raising the 
public’s awareness and improving literacy are  essential components. She cited examples of AI ’s 
contribution, such as to the agricultural sector where there are automated harvest processes, better 
monitoring of food waste, tracking of food production, etc. Other examples included support to 
people wit h hearing impairments, such as real -time translations, which also promote intercultural 
communication. However, the question remained, if we have all these benefits, why do we also see 
reports of why AI is dangerous?  
To answer this, Ms Ndiaye drew attentio n to the fact that the people who are developing these models 
and technologies, tend to be from powerful private institutions and research centres, who may have 
other objectives (such as profit) than just achieving social good. Most of these advances are u sually 
applied to encourage consumption, and therefore only benefit the tech companies themselves. This 
is compounded by the lack of regulation of these tech companies, which also use our data to drive 
their practices to motivate targeted advertising to in crease profitability, also known as surveillance 
capitalism. Other issues include bias in AI, due to the nature of the data input into the data sets, which 
can lead to discriminatory results. AI and resulting decisions are only as good as the data it is ba sed 
on. The abuse of power and resources by the tech companies is a result of a lack of consequences and 
having more policies in place, will contribute to addressing these concerns.  
She suggested that policies should contain the following three aspects: 1)  raising public awareness 
about AI and its applications, 2) policymakers need to understand the workings of AI, to better know 
how to respond to the need, and 3) creating new standards toward improving transparency. In 
conclusion, there is a strong need fo r inclusion and diversity in both policy creation and AI 
development.  
Some NGOs are already working towards achieving this, for example, CIFAR ’s AI Futures Policy Lab 
Toolkit  [36].  46 
 Sheila Beladinejad  
Women in Artificial Intelligence and Robotics: A feminist  perspective  [37]  
The presentation focused on elements of AI, its applications and challenges; how digital 
transformation and AI relate to access to information; the impact of gender disparity in AI; and what 
can be done collectively to address inaccessib ility to information for the marginalised population. 
Together with this, Ms Shiela Beladinejad provided an overview of “Women in AI & Robotics ” [38], 
their mission, programs and how one can collaborate.  
Quite importantly, AI was explained to be an umbrella term that contains a suite of technologies in 
which computer systems are programmed, such as AI itself (AI -computers that can imitate human 
intellect and behaviour), including machine learning (ML -statistical algorithms enabling AI 
implementation through d ata), and deep learning (DL -subset of ML using neural networks by using 
unstructured data). These different levels are important to consider because AI is embedded in a range 
of decision -making processes where women are not well -represented. She stated tha t by looking at 
these different levels, it becomes evident to what extent this exclusion is present, and the depth to 
which this must be addressed to address gender disparity. To illustrate this exclusion and disparity, 
she provided statistics, for example - according to the World Economic Forum, only 22% of the global 
workforce in AI is female.  
It was noted that challenges of AI include the dependency on data and the quality of data (for example, 
biased input generates biased output), and explainability. Th ere is a host of characteristics of 
explainability, such as being: interpretable, explainable, transparent, justifiable and contestable. 
Explainability in this instance is the core component because if an AI system is explainable, it will lead 
to transpare ncy and accountability in AI solutions/decisions. AI does present an opportunity for 
women since the digital transformation provides for economic, social, and political growth. 
Consequently, there are systematic and societal barriers to entry which lead to  inaccessibility to 
information, education, and other opportunities. The book by Mary Ann Sieghart, The Authority Gap 
(2021)  [39], was referred to as an elucidating text providing insight into these gender inequalities. 
Following the barriers, recommendatio ns were made to address the AI disparity for women, and this 
includes the removal of all barriers to information access, boosting confidence, addressing imposter 
syndrome and the provision of role models.  
In conclusion of her presentation, Ms Beladinejad q uoted: “If the people on artificial intelligence tools, 
products and services do not resemble the society (gender, ethnicity, physical and mental abilities), 
then their innovation will not have a positive impact on society and there will always be imbalanc e”. 47 
 Adriana Labardini  
Cognitive Justice  [40]  
 The originator of the term - Cognitive Justice was Professor Shiv Visvanathan  [41] from India who 
promoted the notion of diverse epistemologies. In her presentation, Ms Adriana Labardini pr ovided 
an overview of the concept of cognitive justice as well as the importance of changing the paradigms 
of what we deem as knowledge. She stated that Cognitive justice underscores, and directly relates to, 
indigenous knowledge and argued that all forms of knowledge have the right to coexist, and no form 
of knowledge can assert itself as the only claim to truth.  
Thus, Cognitive injustice included the exclusion of knowledge of women, indigenous people, etc. But 
now with climate change, we are asking how d id indigenous communities relate to and work with 
nature to be in harmony? Through Land, water, spiritual belief, and alignment. Ms Labardini 
established that cognitive justice is fighting for recognition with other knowledge as it wants to do 
justice to o ther types of knowledge and aims to be extremely inclusive.  
She went on to state that there are a couple of guides out there to help guide the analyses of data 
sets, to ensure bias does not creep in and affect analyses and findings, e xcluding other minority groups 
or types of knowledge. Many of these technologies were not designed with safety, privacy, and 
protection in mind thus, she suggested that we all join with a multidisciplinary approach to support 
inclusive design.  
She concluded that Artificial intelligence needs to acknowledge the need for such pluralism, embed it 
and thus ensure that it is inclusive and supportive of diversity. Doing so will allow AI to use 
decentralised, diverse information as an input  to its predictions so that they are unbiased and richer 
in knowledge.  
 
Diana Paredes  
Reimagining Finance with Agile Regulation Technology  [42]  
At Suade  [44], artificial intelligence and machine learning are used to increase the capacities of 
supervisors an d central bankers in a way to have better access to information. The aim is also to 
increase capacity and access to information for the betterment of society, as a stable financial system 
means a stable society. Using AI and ML does help with building back  better, as we have seen with the 
devastating impact of the Covid -19 pandemic, but also our capability as a global society to act together 
to be more efficient. There has been a big, coordinated effort which is inspiring. With the collection 48 
 of analytics, these are being sent back to the regulator to help improve the standards of digital 
regulatory reporting.  
Ms Diana Paredes stated that following the financial crisis in 2008, many systems were put in place to 
help support the financial system to become mor e stable. She noted that based on the experience of 
2008, regulation has improved. Now, it could leverage Covid -19 to ensure that financial firms become 
more agile and prioritise digital infrastructure and services. So, both financial and health crises hav e 
contributed to regulation improvement and better data standards. Inadvertently, better data 
standards lead to better software. These considerations contribute to discussions around fintech  – 
financial technologies – and regtech – regulation of technologies. As an example, you want access to 
data, but you must also regulate how that data is used and managed so as not to contravene people ’s 
rights.  
She summed up her presentation with the prioritisation of responsibility for profit,  stating also that 
access to data has importance, not merely due to its contribution to the creation of good technologies, 
but also because it allows one to act on the frontiers of development allowing for agility through 
efficiency and coordination. These  considerations encompass what is meant by agile governance as 
discussed by the World Economic Forum  [44]. Utilising AI is not only a utopia but a reality, however, 
this reality must contain freedom of access to information without jeopardising the economy.  To 
achieve this, agile regulation is required which does not prevent innovation whilst protecting society.  
 
Chuck Howell  
Enabling the Right to Know “Left of Algorithm ”: The need for early Sociotechnical System (STS) 
consideration s [45]  
A quote leading this presentation shed light on the theme: “We must be careful how we fix what we 
do not understand ”, by Fred Brooks in The D esign of Design. Chuck Howell started his speech by 
emphasising the importance of the AI4IA Conference as it introduced AI into consequential complex 
sociotechnical systems (CCSTS)  [46], impacting people ’s lives. He noted that complex is differentiated 
from  complicated, where the former refers to emergent behaviour, feature interaction and subtle 
coupling which leads to how AI systems affect, and are affected by, social constructs, assumptions, 
and individual and collective behaviour.  
Looking to the left of the algorithm implies that checks and balances need to occur before the action 
takes place. He took for example the prevention of fraud in finances: whereas the initial focus on 
detection would have occurred during the payment process, and if fraud had occ urred, the payment 49 
 would have been recovered and/or fraud investigated, the detection and prevention must occur 
sooner on the continuum. This involves having appropriate statutes and policies in place during the 
programme design, have fraud and error detec tion during an applicant ’s preparation as well as during 
the processing phase. Should a potential error or fraud be detected before payment is effected, then 
the payment can be stopped in time. This saves both time and money and reduces opportunities for 
fraud to occur.  
One of the approaches towards achieving this, particularly in the design phase, is a participatory design 
that considers inclusion and recognition of diversity. In other words, it can be phrased as “no about us 
without us ” [47]. This will hel p to address racial, class, gender and cognitive biases within an algorithm 
and examples are provided of this occurring within a health system  [48]. Looking at data and models 
alone is not sufficient since the cost of a health system and consequent health c are is not race -neutral.  
Another aspect is the right to know versus the capacity to know, where the roles of trusted proxies in 
representing operators and stakeholders come into play. Unfortunately, everyone cannot engage 
individually with every aspect of a system, therefore some proxies represent various stakeholder 
interests during these social constructs.  
Thus, it is imperative that these systems, and proxies, should be transparent to promote trust and 
confidence. It is not just about Explainability, but  the right to know in itself  [49].  
 
Hero Laird  
Ethics, Artificial Intelligence and the Law: A truth about stories  [50]  
Hero Laird started her presentation off by introducing The Digital Law and Innovation Society 
(DLIS)[51], a student group at the University  of Alberta Faculty of Law promoting familiarity with digital 
law topics and the responsible and effective use of technology in the law. She sketched the context by 
indicating where law and AI met and conveyed that due to the proliferation of AI technologi es and 
especially the speed by which it is evolving, the law is failing to keep abreast and articulate the 
requirements to ensure human rights are protected. She suggested that a solution is to start 
articulating legal protections against the loss of auton omy and privacy, as well as mitigating 
discrimination and stigmatisation. In essence, if technology can shape the law, then the law can shape 
technology. This might be done through the inclusion of a broader set of social norms and ideas that 
were not whol ly included in the design, implementation and use of these emerging technologies.  50 
 In the context of stories, Ms Laird provided a quote by Thomas King: “The truth about stories is, that ’s 
all we are ”. This pertains to how we co -evolve together with law and technology, meaning that AI also 
has aspects in common with the law, which creates strong narratives that can deflect and even 
dampen a sense of agency in society. She noted that interestingly, in terms of stories/narratives, AI 
and law can both take on th ese gigantic, nearly mythic proportions, and this holds implications for 
ethics. How will we act? How will it impact society? She identified that if AI is shaping our society, it 
might mean we are not. In other words, if one can access information, however , is not involved in 
shaping or defining it, then how will one be included in the design of AI? During the presentation, 
examples of stories – based on others ’ experiences – were shared by Ms Laird.  
In the final reflection on where law and AI meet, she con cluded that it is the crucial site of exercise for 
ethics, for it questions ethical considerations of technologies.  
 
Susan Juliet Agwang  
Access to information and Artificial Intelligence  [52]  
The presentation referred to the Africa Freedom of Information Ce ntre  [53], a pan -African 
membership civil society organisation promoting the right to access to information, transparency, 
accountability as well as freedom of expression in Africa. Susan Juliet Agwang stated that as 
stakeholders gathered globally, both on - and offline, it was important to underscore the access to 
information, particularly insofar it related to emerging technologies brought on by the human drive 
to innovate and to provide solutions to problems as they arose. She pointed out that one of these  
solutions was AI, as it had been integrated into our digital infrastructure.  
She emphasised that in the quest to achieve the Sustainable Development Goals (SDGs), we required 
all the tools that could empower society, such as with the instrumental help of online learning during 
the Covid -19 pandemic. This had provided a mechanism to promote access to information. Similarly, 
AI had been facilitating the free flow of information, had supported states to manage and control the 
spread of Covid -19 and had enable d collaborative solutions such as vaccine research and robotics. 
Conversely, it had also brought with it some challenges. Article 19 of the Universal Declaration of 
Human Rights (UDHR), protects and promotes the right to freedom of expression. However, sev eral 
nations had utilised AI to restrict freedom of expression, or even used AI to curtail the enjoyment of 
fundamental human rights. Ms Agwang provided the example of the breaching of people ’s privacy to 
collect personal information when using the interne t as many of us failed to read the terms and 
conditions when accepting “cookies” when visiting a website. In the conclusion of her presentation, 51 
 she stressed that AI is an opportunity that we needed to realise, whilst remaining cognizant of the 
challenges it posed particularly to our human rights.  
 
Claire Nelson  
XYNOGENY? How we share decision -making in the age of AI  [54]  
Claire Nelson's presentation began with the definition of Xynogeny. Xynogeny is the production of 
offspring completely different from the parent. So, the question arises in the marriage of human 
intelligence and artificial intelligence, will we still recognise ourselves?  
She emphasised the state of future shock that we are currently in and shed light on the characteristics 
of this state wh ich were:  
• Complexity (multiple key decision factors),  
• Volatility (rate of change),  
• Ambiguity (lack of clarity about the meaning of an event)  
• Uncertainty (unclear about the present).  
Currently, it seems as though we are caught in a race between hu man skill as a means and human folly 
as an end. The AI revolution is transforming economies, jobs and even society itself. And within itself, 
it contains both promise and peril.  
She proposed that concerning our future we must ask what kind of future we wan t and for it to be 
aligned with the Sustainable Development Goals and the consideration of smart futures.  
To share our future decision -making, we should be resilient and transformational in our thinking and 
rights considerations. These include the AI and U se of AI rights; Minority and Gender Rights; the Use 
of Data Gathering Technologies; the Use of Decision Support Systems and stakeholders who are 
involved in the design and use thereof; Earth Rights versus Human Rights; Human Rights versus 
Corporate Rights ; and then finally Access to Information Rights.  
Co-creation – which involves inclusivity and diversity – is certainly the main feature surrounding 
decisions regarding AI design, development and deployment. An example of this is the theme of World 
AI Day i n 2022 “AI as a Public Good ”. In addition, this is a “call to affirm the importance of cherishing 
AI as a global public good, and explore what can be done in the design, development, and deployment 
of AI to advance transparency and empowerment leaving no o ne behind; [as well as] recognising the 52 
 fundamental system changes that AI will have on society, that is, human rights, government and 
governance and our evolution to sustainable futures ”. The notion of a public good is elaborated on 
together with the util isation of Scott Barrett ’s Taxonomy of Global Public Goods  [55] to illustrate how 
it can be an aggregate effort such as global climate change initiatives.  
Other examples were provided on the application of the Barrett Taxonomy to AI as a Public Good, 
applic ation of  Isaac Asimov ’s Three Laws of Robotics, and applying Japan ’s Ten Principles of Robot Law 
(one can also replace robots with AI).  
So, in terms of Xynogeny, how might the future emerge  [56]? The basic bricks of research are 
applicable here such as who, what, when, which, where, when and how will life emerge in 2030, 2040, 
2050, etc.? Examples of initiatives – Imagine 2050 – that attend to this include the LivWe ll Corporation 
which looks into AI inf the AfterLife, with proposals of a curatorium that allows people to live well in 
their 90s due to progress in research and treatment. Other potential considerations of future decision -
making and social lives include E lderLife, AI and Smart Systems in the home, AI in SpaceLife, AI in 
BeautyLife, and AI in ZenLife. These examples encompass transportation, manufacturing, healthcare, 
education, media and customer service. Extended from this, the jobs of the future include EI ethicist, 
Coding ethicist, Telesurgical AI Tech, Robot recruiter, Avatar design -security consultant and Education -
technology integration specialists.  
Sure, all these opportunities sound exciting, however, the fact is we have to be ready to meet this 
future by getting smart and being equipped with the right attitude and abilities. This helps us to think 
about the design of the products, policies, programmes, processes, and services that are integral to 
our shared future. Underscored by these deliberations  is the absolute imperative to promote AI 
literacy and its competencies. To achieve this, we need smart leaders and smart citizens!  
 
Jason Lewis  
Future Imaginaries through indigenous Artificial Intelligence  [57]  
Jason Lewis started by talking about the fut ure imaginary. He said it was composed of a couple of 
things:  
• It is a vision of the future shared by a group of people and used to motivate change in the 
present;  
• It provides communities with a shared vocabulary for discussing the future and strategies for 
getting to the future they desire;  53 
 • It centrally incorporates capacity -building within the community so that the community can 
take control of how such futures get built.  
According to Mr Lewis, future imageries contain a set of strateg ies for creating worlds that we choose, 
and want, to have. Much of the work and projects currently engage with indigenous communities to 
accommodate their needs and vision and support their experiences in building a future that recognises 
them. The future imaginary is currently predominantly Western with a majority representation of 
white people, which comes at the cost of excluding black and brown communities (for example, Star 
Wars represents all these various planets and alien species, but human inhabita nts are mostly white). 
He suggested that we need to practice a future together that is inclusive, enabling diversity and 
supportive or imagining a future we all wish to share. He provided examples of initiatives for 
indigenous futures as well as projects, some of them were:  
• Indigenous protocol and artificial intelligence workshops  
• Indigenous Protocol (IP) AI Position Paper  
• Quartet – a poem series: Concept developed by Jason Edward Lewis (the presenter), with 
illustrations by Kari No, allowing a reflec tion on the type of future one specifically wants to 
have based on one ’s culture and personal experiences and needs  
• A language example is provided in a position paper ʻŌlelo Hawai ʻi translation by ‘Ika’aka 
Nāhuewa: This enables one to learn about technologies within one ’s local language and one ’s 
community context. This might also enlighten the fact that indigenous co mmunities may 
interpret artificial intelligence differently compared to Western dominant interpretations and 
frameworks of artificial intelligence.  
• ‘Anu ’u ʻŌlelo Programming Collective for a Hawaiian language version of C -sharp  
• Pioneered by Kari Noe, Kalani Bright, Nathan Nahina, Kauwila Mahi, Maui Bartlett and Kainoa 
Keanaaina  
• Advised by Dr Noelani Arista and Prof Jason Edward Lewis  
In essence, what does it mean to learn about science and technology within your language? And what 
are the potential i mplication if our future imageries contain non -humans?  
 
References  
[27] https://youtu.be/5Ldsa4Yygto  54 
 [28] https://www.ohchr.org/en/hrbodies/cerd/pages/cerdindex.aspx  
[29] https://youtu.be/_NBmE89MJZo  
[30] https://youtu.be/h5jUZwPepB0  
[31] https://skoll.org/session/sko ll-world -forum -2021/decolonizing -data/  
[32] https://nexleaf.org/  
[33] https://nexleaf.org/data -rights/  
[34] https://youtu.be/gjfK_DwTPU4  
[35] https://youtu.be/62Zcz9CZvlA  
[36] https://cifar.ca/ai/ai -society/ai -futures -policy -labs/ai -futures -policy -lab-toolkit/ 
[37] https://youtu.be/Ev0oIsQt7Bk  
[38] https://www.womeninairobotics.de/  
[39] https://www.theguardian.com/books/2021/jul/16/the -authority -gap-by-mary -ann-sieghart -
review -why-men -are-still-on-top 
[40] https://youtu.be/SqUldHaBkl0  
[41] https://www.india -seminar.com/2009/597/597_shiv_visvanathan.htm  
[42] https://youtu.be/UKF_mivJg vA 
[43] https://suade.org/  
[44] https://www.weforum.org/communities/gfc -on-agile -governance  
[45] https://youtu.be/GWMcNLuXnRA  
[46] Knowles, B. and Richards, J.T., 2021, March. The Sanction of Authority: Promoting Public Trust in 
AI. In Proceedings of the 2 021 ACM Conference on Fairness, Accountability, and Transparency (pp. 262 -
271).  
[47] https://partnershiponai.org/methodsforinclusion/  
[48] Benjamin, R., 2019. Assessing risk, automating racism. Science, 366(6464), pp.421 -422.  55 
 [49] Knowles, B. and Richards,  J.T., 2021, March. The Sanction of Authority: Promoting Public Trust in 
AI. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 262 -
271).  
[50] https://youtu.be/Pd3gQosFehg  
[51] https://dlis.ca/  
[52] https://youtu.b e/BL6fn60b99Q  
[53] https://africafoicentre.org/  
[54] https://youtu.be/RXXzSGoo0KQ  
[55] https://www.scottbarrett.org/global -public -goods  
[56] https://www.futuresforum.org/  
[57] https://youtu.be/bhsVn_LfgHk  
[58] https://youtu.be/bhsVn_LfgHk  
[26] https://yout ube.com/playlist?list=PLTULETeBko5EPdf4OKnm6GlseSq5tldyX  
[26] https://youtube.com/playlist?list=PLTULETeBko5EPdf4OKnm6GlseSq5tldyX  
 56 
 9. AI and Healthcare  
 
9.1. Introduction  
The section about healthcare was of utmost importance. AI and its roles and responsibilities  in 
healthcare occurred regularly during the conference. This is especially true in the wake and realities 
of COVID -19. Various applications of AI in Healthcare include:  
• Monitoring  
• Clinical decision -making  
• Treatment options  
• Mining and managing medical data with AI  
• Logistical and administrative applications  
• Clinical trials, training and medical education  
AI impacts Healthcare, especially due to the availability of big (medical) data or vast collections of 
health -related data. Utilising this data, deep learning can solve complex problems by involving high 
dimensional data to guide the best healthcare option s. The explosion of the AI health market has 
progressively increased from 2014 to 2021, and it will only continue to grow. As a result, one can also 
see an increase in academic publications.  
 
 
 
57 
 Esteemed speaker: Velu Nair  
Why AI is needed in Healthcare  [60]  
Lt. Gen. Velu Nair started by talking about how technology has become embedded in our lives and by 
extension in health care services as well. AI can assist with the detection of health concerns (i.e. 
cancerous moles) and even the prediction of diseases and diagnoses, such as cancer.  
 However, he questioned if can AI meet the demand of unmet clinical needs, such as addressing the 
shortage of clinicians? WHO prescribes one doctor and three beds per thousand population (1/1000), 
however in  reality the figures are lower. There is a much higher demand for patients to see doctors, 
than the help that can be supplied. It was noted that India has prioritised this requirement and now 
has a ratio of 1.34/1000. Very emphatically, AI can provide effe ctive solutions!  
He placed emphasis on the fact that AI models be embraced. It is imperative that the end -user be 
involved from the onset, and it must be AI for ALL, not some. AI must bridge the gaps between haves 
and have nots, rather than contribute to t he digital divide. AI contributes to medical assistance via the 
service delivery of a virtual nurse, who does not replace a real -life nurse, but they can provide useful 
information, assist patients, and give recommendations towards health care options.  
According to Lt Gen Nair, there are three approaches: 1) Rule -based approached, 2) Machine learning, 
and 3) deep learning is a more advance field of machine learning which makes use of neural networks 
to solve more complex problems. Ob jectives of AI are for:  
• Increased predictions for accuracy (i.e. look at the data from the first, second and third waves 
of Covid -19 in order to better prepare)  
• Decision making becomes more precise due to the shortlisting of possibilities  
• Solve complex pro blems such as with genetic research  
• High level computations are the future of AI (virtual models for clinical trials and genomics)  
Lt. Gen. Nair provided examples, such as the Indian Myeloma Academic Group (IMAGE) – 
Care4Myeloma, Haemophilia tracking apps,  TB diagnoses and MRI scanning and diagnoses, smart 
socks and bras, and popularly, smart watches and activity trackers which all lead to the visualisation 
of models to improve health and wellness.  
There are also several beneficiaries, such as the patients,  the healthcare providers, AI developers, 
payers, and insurance agencies and finally, pharmaceutical companies. Pharmacovigilance, which is 
the identification of medication errors, can improve by the utilisation of AI. It can assist with the:  58 
 • Detection  
• Assessment  
• Understanding and  
• Prevention of adverse effects and other drug and devices causing potential safety problems 
because of errors.  
He identified that ethics and limitations of AI are perhaps the most complex considerations. In terms 
of responsibility, it includes the notions of transgression rights and requisite regulations and 
regulators. Though, AI will essentially improve decision -making and make the lives of doctors simpler 
and safer, it will not replace the important role of doct ors. Will patients accept AI (or robots) and can 
it replace the human touch and empathy? Then ofcourse, AI is also faced by other ethical issues 
including hacking and malware, which also have legal implications. Cost effectiveness are crucial to AI, 
if it is not affordable, it will not be accessible and will inadvertently widen the gap between rich and 
poor communities and countries. Limitations also include bias in machine learning, GIGO (garbage in 
garbage out).  
Initiatives in India that utilise AI are: H ealthcare AI Catalyst project, Diabetic Retinopathy, Cancer 
Biobank. There are many AI -assisted medical applications currently in development and it will increase 
in future. Biases must be addressed to improve the machining learning models which base their  
calculations on the input data. And finally, although AI certainly provides many benefits, the social, 
economic, ethical, and legal concerns must be addressed to ensure the challenges are mitigated going 
forward.  
Lt. Gen Nair quoted the Hippocratic Oath " If I cannot do good to a patient, then I should do no harm" 
and concluded that trust is very important, especially between AI and humans.  This trust must be 
developed especially within villages and the rural populations. End -user is very important, for 
collaboration from the beginning. The architect must meet the buyer. Computational scientists must 
engage with users. Being replete with information, we need to apply the right filters to best 
differentiate what is needed.  
 
References  
[60] https://www.youtube.com/watch?v=FAKAAHzhItk  
[59] https://youtube.com/playlist?list=PLTULETeBko5G17bEsI_S_WRnb3rarheRd  
[59] https://youtube.com/playlist?list=PLTULETeBko5G17bEsI_S_WRnb3rarheRd  59 
 10. Media and the Right to Know  
 
10.1. Introduction  
Showcasing the role of the media and the right to know, ten presentations – from the United States 
of America, Brazil, Colombia, Jamaica, United Kingdom, India, Zambia, South Africa and India – dealt 
with this topic. Andrew Bruce Smith opened the session with his present ation on the impact of 
Artificial Intelligence on Public Relations, Communications and Reputation. He did so by looking at 
three focal areas, which included the Ethical in AI, the impact of AI and the reputation based 
implications of AI usage within the do main of Public Relations. He reminded us that just because 
something can be done, it does not mean it should be done. The cornerstone of ethical decision -
making, especially in the role of AI, is to make thoughtful and thought -through decisions. Public 
relations officers should ensure that no decision that is made – by a human or AI – should ever cause 
harm to anyone.  
In considering avoiding harm, Shalabh Upadhyay presented on AI ’s battle with fake news. It was noted 
that before the internet and information deluge, information was finite and depended on journalists 
to collect, curate and present it. However, today, with emergent technologies such as AI, the 
proliferation of information (experienced as information overload) appears messy, voluminous, un -
curate d and even manipulated. He argued this is not all bad: for there are exciting opportunities for 
current and future journalists to harness AI to improve their reporting processes. AI and other 
60 
 technologies may continue to develop, but so will our abilities as humans to utilise these. Therefore, 
it is incumbent on society, and especially journalists, to ensure they understand how these 
technologies work and how they can be used to shape the future.  
The media and sphere of journalism do not only impact the liv es of adults. Algorithmic awareness also 
heavily features in the daily routines and interactions with youth. Kara Brisson -Boivin, from 
MediaSmarts, presented a study on conversations with young Canadians about algorithms and AI. This 
extremely insightful s tudy looked at the assumptions and lived experiences of the youth, via an 
interactive study to gauge their awareness of the implications and workings of AI and big data 
collection. The study both captured their pre -study opinions and compares these with th eir responses 
following a three -step game -based educative session. It was indicative of the initial levels of trust 
displayed by youth in engaging with online and social media platforms, but also their frustration and 
discontent when realising the implicat ions on their personal information and profiling based on 
aggregate data.  
These considerations led to Marco Schneider ’s presentation on the right to know what ? One can 
promote the right to know in general, but how is the quality and reliability of availabl e information 
guaranteed. Not all information needs to be known, such as information about state security and an 
individual ’s bank account details. On the other hand, there can be information available that is 
dangerous, misleading and hurtful. The right t o know is therefore not absolute, and neither is all 
information necessary. That is why the qualitative, and not just the quantitative, elements of 
information access need to be considered within a fair and just society. When considering a fair and 
just so ciety, Nazima Raghubir asked who are the guardians of the information held by a society, 
organisation or entity? She recommended that the media, or broadcasting agencies, must be part of 
the industry to promote awareness of media and information literacy, to best inform and guide the 
citizenry. This is especially true in the current challenging times.  
One might ask how possible it is for a broadcasting agency, media institute or communication 
regulator to ensure such access and quality standards are integra ted and maintained? This is the 
perspective Ernesto Orozco brought to the table as a representative of the Communications 
Regulation Commission in Colombia. He provided an overview of steps taken by the regulator to 
improve diversity in media content deliv ery, not only in terms of multilingual capabilities but also in 
consideration of marginalised, vulnerable or rural communities. Not only do they seek to improve 
audio -visual content, but they also want to avoid content that might infringe on the rights of others, 
such as, for example, excluding hate speech. The regulator enriches their practices by conducting 61 
 academic research, and the results are fed back into regulations and service support to meet the needs 
of the public.  
Jan Vermeulen seconded the role of the media in promoting and upholding a democratic society, 
especially insofar as it is seen as the fourth estate (or the fourth pillar of a democratic society). On the 
right to know, and the issue concerning the “what”, Vermeulen expanded on the instanc es of 
information that should not be known, such as the identities of recently deceased, witnesses, victims, 
minors and suspects of court cases and even the publication of graphic images. If the distribution of 
information is not managed, there can occur a n erosion of trust as well as the proliferation of mis - and 
disinformation. The public can easily be manipulated by the selective use and curation of information 
to meet the objectives of those in power.  
Daniel Sikazwe stated that AI can help with journali sm and the citizens ’ right to know. It provides tools 
to evaluate information, distribute and package it, but also to verify it. Conversely, it is acknowledged 
that it can be used as a tool to harm or influence the public. Essentially, AI can help create a  truly free 
press that is not defined as being homogeneous but instead known for being welcoming of diversity 
and the promotion of value pluralism. In addition, the democratisation of information puts pressure 
on traditional media to raise the standards of  research, consolidation, curation and communication of 
information.  
It would be very difficult to discuss the communication of information without introducing the 
importance of language diversity. Especially the accommodation of local, native and mother t ongue 
languages. This important topic was raised by Thoriso Maloka who presented from a South African 
context where there are eleven official languages. AI makes media and information more accessible 
to communities through its ability to provide speech -to-text services, sub -titles and automatic 
translation. Examples were provided of organisations that have developed radios which require less 
electricity to function within rural settings that do not have regular or trusted electricity provision. In 
a society  that is dependent on the quality and accurate information – for example in the build -up to 
elections – it is imperative to make information available in a language and medium that the youth, 
elderly and non -English speakers can access.  
Kristen Tchernescho ff supported this notion by recognising that minoritized and indigenous languages 
have been displaced by dominant languages through colonisation and forced assimilation. This led her 
to present digital language activism and the process of language reclamat ion. She advocated for a 
positive approach, stating that dominant discourses about language reclamation tend to focus on the 
decline of languages spoken in the world. Instead, there are numerous instances where minority 
languages are being revitalised by f amilies, the youth and community members.  62 
 These practices are very much enabled through the use of digital spaces, which is making it more 
possible for communities to connect and share their language experiences and histories.  
 
10.2. Overview of presenters  
Andrew  Bruce Smith  
The impact of Artificial Intelligence on Public Relations, Communications and Reputation  [62]  
AI already has many implications for all aspects of Public Relations. Andrew Bruce Smith presented 
various key focal areas in this presentation, such  as: 
• The ethical use of AI in Public Relations Practice  
• Impact of AI on Public Relations work  
• Reputational implications of AI use  
 
Steve Jobs's quote "Computers do not make mistakes, humans do" led to Mr Smith's presentation.  
Thereafter, he stated that machines make mistakes only because humans have either input the wrong 
data, have forgotten to factor something into our decision -mak ing, or simply because we have a poor 
understanding leading to mistakes. Depending on AI to make and guide independent decisions can 
lead to unintended consequences, hence the responsibility lies on humans to ensure this is mitigated 
by inputting correct a nd unbiased data. However, ethics is not only about avoiding mistakes. It is about 
doing good and promoting right behaviour as opposed to wrong behaviour.  
AI can be used to streamline PR and it also encompasses how AI is replaying the human workforce, 
such as the usage of chatbots. The data collected is aggregated, can be stored, analysed and used to 
improve service delivery. But it can also be biased due to a limited scope of engagement of certain 
sectors of society. AI tools can be used on purpose to 'di sinform' - where fake news is deliberately 
distributed and used to influence people ’s thinking to persuade them to do things inadvertently. Thus, 
an ethical framework is needed to help figure out what is the right thing to do. Regulation and 
legislation do not keep up with technology development. How do we go about considering the ethical 
implications of a particular tool? However, it should be emphasised that AI must contribute to the 
public good. AI is encouraging PR professionals in the sense that it migh t motivate staff to upskill. It is 
also probable that PR professionals are using AI tools without evening knowing it!  63 
 He reiterated the fact that though AI can be used for social good, it does contain dangerous elements. 
Thus, just because something can be done, does not mean it should be done. That is the core of ethical 
decision -making, to make thoughtful and thought -through decisions. The best test for an ethical 
decision is to see whether it stands up to scrutiny based on thought, intent and execution before 
arriving at our decisions. Ethics is difficult in everyday life, so by adding AI and machine learning and 
other emerging technologies, it becomes even more complicated and is amplified in their impact on 
individuals and society at large.  
He insisted that PR professionals should ultimately not make any decisions that can cause anyone 
harm, but anyone at a disadvantag e, or unconsciously create bias. PR professionals offer strategic 
advice to colleagues and organisations to make ethical decisions, almost like playing a guardian role. 
AI will radically change the way we live and work, those that know how to use AI will b enefit from it, 
and those that do not might become disenfranchised. Big questions arise as to the governance of 
these technologies. In conclusion, any of these decisions and resulting actions will have an impact on 
an organisation ’s reputation.  
 
Shalabh Upa dhyay  
Artificial Intelligence ’s battle with fake news  [63]  
Shalabh Upadhyay's presentation aimed to discuss AI and its ramifications when it comes to 
journalism, storytelling and the wider society. Journalism – and its medium – has evolved as the 
realities  of our societies have changed. Journalism uses various means of communication as tools to 
fit a larger objective, which is value creation for society.  
Before the internet, information was finite, and it was up to journalists to make information more 
acces sible to the public. In addition to this, journalists also broke the news firsts to keep citizens 
informed whilst communicating directly to the masses via print and broadcast media. Many of these 
aspects changed with the advent of the internet. For example , mass communication is now a feature 
of social media platforms. Conversely, even though there is now a surplus – or infinite – the amount 
of information available, we might argue we do not feel more knowledgeable.  
Mr Upadhyay noted that fake news existed before AI since it is essentially propaganda that has been 
used by the government to manipulate and shift perceptions many times. However, it is now seen to 
be specifically a problem for our generation, due to the transition from a non -digital to a digital  society. 
The challenge now is not necessarily to address fake news but to question what the role of journalists 
will be going forward.  64 
 AI, like any tool, can be used for right or wrong. Certainly, people will use AI to proliferate fake news, 
but AI is als o used, in the New Emerging World of Journalism (NEWJ)[64], to look at how information 
can be made more accessible and streamline delivery. Herein lies an opportunity for current and 
future journalists to adapt and understand these new technologies that ar e coming through and see 
how they can be best implemented to serve the greater purpose of journalism. Even should AI become 
much more complex in the future, our ability to utilise these tools will also expand. Journalism ’s utility 
as the source of credible  information can therefore be greatly enhanced.  
He concluded that those who have never considered journalism as a profession, especially young 
students, should consider it and as aspiring journalists, they must be bold and learn about these 
technologies an d how they work.  
 
Kara Brisson -Boivin  
Algorithmic awareness: Conversations with Young Canadians about Algorithms and AI  [65]  
Kara Brisson -Boivin began her presentation by giving a background on the organisation -MediaSmarts  
[66]. She t alked about a recent study, that applied game -based approaches, conducted with young 
Canadians on algorithmic awareness, with the following two aims to gauge insight:  
1. How do young Canadians understand the relationships between AI, algorithms, privacy and 
data protection;  
2. Benefits and concerns about recommendation algorithms,  
The project was also used to inform and call for more algorithmic literacy tools and resources to 
increase protection in digital spaces. The project methodology is elaborated on, explai ning the 
timelines (2020 -2021), target groups (13 -17), platforms (virtual platforms such as Zoom), etc. The 
game prototype, #ForYou, was specifically developed for this project and was designed to be played 
collaboratively over three phases.  
Some of the fi ndings of the project included (but were not limited to):  
• The youth pointed out the attention between helpful content filtering and concerning content 
narrowing;  
• Participants of all ages pointed out an algorithmic content narrowing effect which includes an  
excess and overload or saturation of similar content;  65 
 • This led to rising concerns around default settings which platform and content creators use to 
manipulate algorithms to optimise engagement and manufacture consensus;  
• Participants were concerned when a  false sense of social consensus was generated, for 
example on political topics and climate change;  
• They felt frustrated by the powerlessness to change this algorithmic architecture;  
• Regarding the usage of personal information, most participants had few re servations about 
algorithms recommending entertainment and leisure content, however, they felt unsettled 
by the invasive corporate surveillance strategies;  
• They felt uncomfortable that their data were lumped together to form data aggregates to 
train algori thms without their knowledge – no longer were they, unique users, with unique 
needs, but recommendations were made based on guesses of other users similar to them.  
• Many participants were aware of bias and the role that it can play and the repercussions it 
may have for online businesses and users. It was noted that these companies need to be 
aware of such biases to ensure discrimination, racism and marginalisation do not take place.  
In many instances for the youth, it was the first time they had made these c onnections between 
algorithms and the platforms and technologies they use. These so -called ‘A-ha’ moments made them 
want to speak in -depth about the impact of AI on their lives. Scholarship, science and technology 
studies have explored children and youth ’s meaning construction in the ‘parasocial ’ relationship with 
technology (voice assistants such as Siri, and internet -connected toys). This can be concerning since 
an illusion of intimacy or friendship is created with an algorithm, which is not human. These 
technologies do not understand emotions or what is right or wrong. A trend amongst young Canadians 
is that they tend to view the online world through the same lens as they view the offline world. At the 
inception of the discussions on AI and algorithms, pa rticipants approached them with the notion of 
‘being a friend ’, but as the discussions continued, participants realised more than their views on this 
relationship may be problematic. These moments led to conversations about trust, responsibility and 
contro l which translated into a series of recommendations.  
The findings from this project provide key role -players – such as researchers, policymakers, and the 
tech industry leaders – with important considerations for the way forward to address issues about 
prot ection, awareness, control, and transparency. The development and implementation of AI literacy 
curricula are strongly recommended to improve awareness and education.  
 66 
 Marco Schneider  
The right to know what? From the corporate media gatekeeping to the AI co nfirmation bias filters 
of big tech corporations  [67]  
In this presentation, ethical and political questioning was proposed by Marco Schneider. This 
questioning pertained to the contradictions between the right to know and the reliability of the 
information. He stated that these contradictions even extend to c orporate media gatekeepers and 
their generally conservative ideological bias, which currently manifests as right -wing misinforming 
confirmation bias. All these instances are mediated by algorithms. Other themes that arose in this 
presentation included cred ibility; self -deception; the notion of private hegemonic apparatus; the 
theory of gatekeeping; big tech corporations, extreme right -wing growth and infodemic.  
If artificial intelligence means computing devices that can perform smartly, one should first dis tinguish 
between instrumental intelligence and ethical one. Whereas the former deals with efficiency, the 
latter questions “for what”? When discussing AI about the general issue of information access and the 
right to know, the point is to ask what kind of information do we seek to make more accessible? 
Examples of accessible, yet damaging information such as seen in the current infodemic, consists of 
hate speech, right -wing propaganda, anti -science and all kinds of negating information and practices. 
Perhap s then the focus should not only be to provide access as such, but also on how AI could better 
filter “good” from “bad” information. Consider for a moment one of the main information problems 
– the infodemic – because of going from scarcity to an abundance  of information. This problem then 
leads us to the philosophical issue of the quality of information, together with deception, self -
deception, confirmation bias, the social construction of cognitive authorities, credibility, and 
ideologies.  
The presentatio n elaborated on the importance of quality and qualified information, the notions of 
self-deception and confirmation bias, the meaning of cognitive authorities (and cognitive justice), the 
roles of cognitive authorities/gatekeepers, values such as credibili ty and reliability, and the existence 
and maintenance of certain ideologies by the hegemonic apparatus.  
Mr Schneider  believes that information access and the right to know are not only quantitative but 
mainly qualitative issues. Freedom of speech is a majo r civilization achievement, but should not be 
taken as a fetish, as a value apart from others equally or even more important, like commitment to 
the truth, with the public interest, with social justice, with fair information ecosystem. These 
considerations  also extend to AI, which together with its benefits, can also pose harm to society.  
 67 
 Nazima Raghubir  
What Artificial Intelligence means for media in the region in the midst of challenging times  [68]  
Citizens’ right to information an d access to information raises the questions of what that information 
includes and who are the guardians of such information? Nazima Raghubir pointed out that these 
rights have been enshrined in constitutions, laws and regulations across the entire globe, however, it 
does not imply all countries have done so in equal measure if at all. This leads to the role of the media 
– the fourth estate – and the role of journalists in terms of the right to know to achieve the public 
good.  
Subseq uently, what implications do AI hold for an ever -changing industry? Not only is information 
distributed in new ways, but it is also consumed in new ways. Political decision -making impacts the 
nature of, and the methods by which information is communicated,  and the public ’s decisions are 
then based on the narratives which are created by the media. As an example, the Caribbean Media 
landscape has been changed forever due to the growth of news and online social media platforms. 
The influence of AI has become d ebated in the media industry: consider that news is researched and 
compiled by journalists, but then disseminated and presented using AI formats. AI also contributes to 
the spread of disinformation, which inadvertently weakens the Caribbean media landscape . Will the 
media industry be left behind?  
In conclusion, in the absence of strong media and information literacy levels, AI journalism can pose a 
challenge to the citizens. It can however also lead to opportunities for value -additio ns such as a 
greater representation of diversity and inclusion of indigenous communities.  
 
Ernesto Orozco  
Media and the right to information (A Regulator ’s Perspective)  [69]  
At the Communications Regulation Commission (CRC), the right to information is sou ght to be 
guaranteed through studies and projects that strengthen democracy. Not only have regulatory 
functions been extended from audio -visual to television, but also surveillance and control concerning 
content. This function used to be exercised by the N ational Television Authority, which included 
guaranteeing pluralism, the impartiality of information and the promotion and regulation of citizen 
participation in matters that might affect viewers. Services have been extended to include open 
broadcast TV an d sound services at a very high quality. These inclusions of regulations, such as those 
about communications and specialised audio -visual content, are done by the law in Colombia.  68 
 Ernesto Orozco pointed out that through these, two rights have been guarante ed, namely: Pluralism 
and the Impartiality of information, especially in respect of the experiences of users, in terms of 
dissemination, protection and advocacy of the interests of television viewers. It also seeks to prohibit 
the behaviours of those that impinge on these rights.  
He provided an example of Colombia, where to benefit citizens and foster sector development, many 
components have been implemented to provide quality, accurate and accessible content. By 
promoting citizen pluralism (external), the internal pluralism of the CRC has been encouraged together 
with the promotion of pluralism in audio -visual channels. The provision of continuous information is 
requisite in the participation and representation of citizens in television media. Studies have continued 
– to measure pluralism – to ensure the CRC remains sensitive to the inclusion of diversity. It also helps 
to understand how the risk for pluralism is fundamental to understand the scenario provided by 
legislation, to guarantee such pluralism of i nformation and sanction behaviour that infringes upon it.  
Understanding the context of the broadcast and communications sectors in Colombia is central. Even 
though there is high economic concentration in Colombia – as with the rest of Latin America – the 
media must remain pluralised in its content provision. Pluralism is seen as a fundamental human right 
that essentially promotes social diversity. It also seeks to include three specific groups: women, people 
with disabilities, and people in rural Colombia. Reference is made to a study targeting broadcast 
content across local, regional and national levels, to gauge the diversity of content, particularly 
concerning television content. The effectiveness and satisfaction of these systems are highly regarded 
espe cially insofar as it meets the needs and expectations of the target communities. This study is 
continuing to ensure that it provides more insight into the performance of these communication 
platforms and systems. Based on the results, decisions will be mad e based on the provision of 
adequate and effective access to content on a variety of platforms, to diverse communities and in 
recognition of the different schedules of these communities.  
Therefore, not only does the CRC (with member states in Mexico, Catal onia and Colombia), seek to 
play a regulatory role, but also wishes to provide academic research to adequately inform and improve 
current media provisions by following a multistakeholder approach.  
Other considerations include media literacy, Over -The-Top ( OTT) media provisions, gender 
representation on television, youth sensitivity and inclusion, and an analysis of the audio -visual sector 
from broadcasting to broadband. This is therefore a global collaboration between academia, industry, 
and the media secto rs. This approach acknowledges the challenges and opportunities posed by an 
interconnected world as realised by an ever -increasing digital landscape and the Covid -19 pandemic. 
Regulators face numerous challenges on this interconnected world and Covid -19 co nsequences, 69 
 especially since it causes shifts in consumer behaviour. It is therefore imperative for the regulator to 
be aware of these shifts in consumer behaviour and changes caused by global events. This will allow 
the regulatory body to be aware of the trends in the sector and translate those into the quality and 
relevant content for the population. Flexibility and innovation are essential to leveraging this digital 
shift, and that is why intelligent services are integrated with regulation.  
In conclusion, the aim of the regulator to leverage the digital transformation are threefold and was 
listed by Mr Orozco as 1) regulation as a tool for the digital transformation of the sector, 2) the digital 
transformation of the regulator, and 3) the exp loitation of data (to promote input to the regulatory 
policy development and improving decision -making). Therefore, a number of strategies are used to 
maximise social wellbeing, foster investment, promote competition and ensure pluralism of the media 
in Co lombia.  
 
Jan Vermeulen  
Technology, Media and the Right to Know in 2021  [70]  
Jan Vermeulen began his presentation by giving the background of the context which informs the 
presentation, for example, by applying investigative journalis m, the biggest cryptocurrency scam of 
2020 was uncovered by utilising chain analyses. Another investigative report that refers to - is Africrypt  
[71]. Pertaining specifically to this presentation, the media is referred to as the “fourth estate ”, or the 
fourt h pillar of democracy:  
1. Executive – Cabinet  
2. Legislative – Parliament  
3. Judiciary – Courts  
4. Free press – Media  
Conversely, in South Africa, much of the executive and the legislative are entrenched in deep 
corruption, also what we now term State Capture. However , together with the judiciary and free press, 
it was possible to hold the executive and legislative to account. It is, therefore, essential – imperative 
– to have checks and balances in place in a democracy.  
He referred to a South African investigative jou rnalism programme, Carte Blanche  [72], and their 
slogan “You have the right to see it all ”. However, the right to know is not absolute, there are some 
restrictions, for example not being legally allowed to reveal the identities of recently deceased, 70 
 witness es, victims, minors and suspects. Other rules contain societal rules such as those about graphic 
images. Other instances are debatable, such as the right to be forgotten (European Union) and keeping 
information secret insofar as its implications on nationa l security. Weighed against national security, 
is the notion of disclosing information for the public good.  
Some obstacles and/or threats to our right to know are elaborated on, including censorship versus 
free speech; internet shutdowns and throttling; access to public records; surveillance, threats and 
attacks on journalists which have a potential chilling eff ect on journalists. It should be noted that in 
many instances court documents are not easily accessible by the public: it is mentioned that it is easier 
to find court cases/reports in the USA. An example is provided of documents required in Uganda that 
were not digitally archived, where someone had to physically go to the archives and manually scan 
and send each page!  
Together with the foregoing, some mistakes take place in information disclosure, such as eroding of 
trust, and the spread of mis - and disinfo rmation to manipulate or misinform citizens.  
In closing, Mr Vermeulan quoted from the computer game, Sid Meier ’s Alpha Centauri ™, “The once -
chained people whose leaders, at last, lose their grip on information flow will soon burst with freedom 
and vitalit y, but the free nation gradually constricting its grip on public disclosure has begun its rapid 
slide into despotism. Beware of he who would deny you access to information, for in his heart he 
dreams himself your master ”. 
 
Kristen Tcherneschoff  
Digital lang uage activism  [73]  
This presentation acknowledged that minoritized and indigenous languages have been displaced by 
dominant languages through colonisation and forced assimilation. Language reclamation can become 
a form of resistance to the dominant hegemon ic forces. Language reclamation can be used to describe 
a social process of re/claiming the appropriate cultural context and value that the language would 
have sustained had it not been colonised or suppressed.  
Kristen Techerneschoff in her presentation hi ghlighted that all languages are vital to the world. and 
one of the spheres impacting language and communication is the internet, which functions as both an 
enabling and disruptive tool. Media in a dominant language can marginalise some cultures, but media  
also makes it possible to capture the languages that are being marginalised and can serve as a vehicle 
for revitalisation by employing language digitisation and preservation methods. She gave examples of 71 
 the International Year for Indigenous Languages in 2019 that promoted marginalised, minority and 
indigenous languages. Another vehicle for revitalisation is recognition by the International Standards 
Organisations (ISO) Code which provide communities with a three -character identifier for their 
language. Th ese and other examples highlight the importance of having a community within the 
language reclamation process.  
She emphasised that reclamation requires the building of infrastructure for a community: speakers 
must find one another by providing an example f rom Louisiana, about preserving the Tunica -Biloxi 
language  [74]. However, due to a lack of institutional support, the project did not flourish and records 
remained stored away in the university and other archives. Donna Perry – a lady whose husband, 
Michael , had his language reclamation journey – drove to Baton Rouge in New Orleans, to visit the 
archives and to make photocopies of these records! This process of bringing her language home lasted 
for nearly a decade. In this process, the family built a communi ty around reclaiming their ancestral 
language through the distribution of media. Now, there are more than 100 active learners (10% of the 
overall tribal population) with 32 new fluent native speakers of which the parents are passing the 
language down to th eir children.  
Previously the dominant discourse about language reclamation focused on the loss of language from 
our world. Instead, there are many individuals and communities actively turning to their heritage and 
cultural languages and many of these langu age users have championed the support provided by digital 
spaces. There are two initiatives to note: 1) Rising Voices which is building a toolkit on how to be a 
digital language activist  [75], and 2) Wikitongue s [76] supports language revitalisation movement s 
through grants.  
 
 
 
 
Daniel Sikazwe  
AI and Journalism  [77]  
Daniel Sikazwe's presentation aimed to look at AI, and  how it helps in journalism in addition to the 
citizens’ right to know. The right to know forms part of a broad range of ep istemic rights and goods, 
like information, knowledge and truth. People desire to have information, knowledge and truth, 
especially in an information -centric society. Sometimes these rights are contravened by governments 72 
 and commercial interests, and even oftentimes by religious interests. Those who control what citizens 
know can exert a huge influence on the lives of citizens, and this is very dangerous in a democratic 
society. This harm can extend to individuals, communities, and even social and political  institutions.  
Stumbling blocks to the right to know were expanded on, such as a lack of transparency, limited 
freedom of expression, and laws which preclude accessible information which also inhibit a free press. 
In short, citizens  must know what their governments are doing! That is why there is usually this conflict 
between those who wish to exercise their right to know against those who seek to prevent it. The 
importance of this can be observed by the vast variety of regulations, policies and strategies in place 
by intergovernmental agencies, multinational entities and civil society organisations, that promote the 
right to know. In turn, if citizens enact their right to know, it helps to improve decision -making and 
promotes the qua lity of policy, laws, and societal development, essentially bridging the inequality 
gaps.  
So where does artificial intelligence come in? AI tools can help to break down these provisions and 
provide access to information that is usua lly kept confidential. By using AI tools, journalists can 
empower citizens to both act as producers and consumers of news, allowing citizens to become more 
active citizens. Conversely, despite the existence of various AI tools, at the moment most media 
institutions are limited by the fact that they cannot use all of these tools (e.g. due to cost factors).  
Additionally, due to information overload as well as data dumping, citizens can become even more 
confused, especially if there is the occurrence of mis - and disinformation. It was noted that this can 
be addressed by journalists who can use AI tools to curate the data received and package it in accurate, 
quality and accessible information. AI can help create a truly free press not defined by being 
homogenou s but instead diverse. Democratisation of information provides pressure on traditional 
media to raise the standards of verification through the application of fact -checking tools. Citizens do 
not want to be distracted by irrelevant information or informati on that clutters their newsfeeds. AI 
can therefore assist in meeting citizens ’ information and news demands.  
As we know, the internet is not a permanent and perfect archive of historical material indexed by 
neutral entities. It is m essy, dynamic, and constantly changing. He suggested that for this reason, it is 
imperative to educate citizens on some of the AI tools for it may assist with finding relevant 
information, fact -checking and verification of news/information received. It mig ht also assist with 
understanding the context, complexity, nuances and dynamics of information resources, which will 
allow citizens to gain a more balanced and objective view.  
 73 
 Thoriso Maloka  
Role of the media in creating access to information  [78]  
Thoriso  Maloka began by considering the role of the media in creating access to information, and the 
impact of current and emerging technologies in making this information available. What is the 
mandate for creating a right to know? Their mandate is to provide in formation that allows for 
informed decisions and the ability to hold institutions and individuals accountable.  
For many of us, specifically, Africans, when having discussions about holding governments and 
individuals accountable, it is something we can ide ntify with since we are going through that period. 
This includes the quality of information as well as receiving it promptly to effectively hold them to 
account. Unfortunately, sometimes that information is lost in the gaps. These gaps are not always 
relat ed to the platform but instead related to the method of delivery, for example, language.  
She shed light on the fact that in South Africa there are 11 official languages, but not all information 
is available in all the languages. In terms of the medium, we still have radio broadcasts which the 
elderly communities have easier access to than compared with podcasts and other social media and 
online news platforms. Notably, if people cannot access information in their language, this information 
is no longer acce ssible, and it then falls through the cracks. Consider for a moment the communication 
of particulars about Covid -19 – such as the specifics of each variant – how is that translated into local 
languages and rural communities? Information is provided to citi zens in a language – English – that 
impedes their understanding.  
How does technology play a role in this? How can the media improve on this? There is this concept 
now of algorithm journalism or automated journalism. In reality, what you hear over the radio  is a 
small percentage of work that occurs behind the scenes. There are aspects of automated journalism 
that can serve communities, such as transcripts of broadcasts and speech -to-text/closed captions on 
television. AI can also be used to recognise voices over the radio, or even facial recognition over 
television, to support remote (or neglected) communities who do not receive information in their 
language. She suggested that we should therefore be cognizant of the ways AI and emerging 
technologies can be m arried with the roles and abilities of the media. A company that achieves this is 
Freeplay Energy  [79] / Lifeline Energy  [80] which provides information access to those who need it 
most and they also develop products and platforms, such as radios. They are p articularly developed 
to not require electricity to mitigate energy provision shortages as experienced in South Africa and 
other countries across Africa and even globally to best serve humanitarian communication.  74 
 Accessibility of information can also be ma de possible where crucial information – such as a manifesto 
of political parties – can be made available without needing to attend election campaigns.  
 
References  
[62] https://youtu.be/30Q9RWKz0aU  
[63] https://youtu.be/_F_O_XdQOSQ  
[64] https://thenewj.com/  
[65] https: //youtu.be/dfNnmkiI9u4  
[66] https://mediasmarts.ca/  
[67] https://youtu.be/OWHj_k_WOpQ  
[68] https://youtu.be/ZjRMqvNpipw  
[69] https://youtu.be/MFfbmfcnN48  
[70] https://youtu.be/SbaKHdNt57U  
[71]https://mybroadband.co.za/news/cryptocurrency/410706 -rise-and-fall-of-south -africas -r54-
billion -bitcoin -brothers.html  
[72] https://m -net.dstv.com/show/carte -blanche  
[73] https://youtu.be/ -yJk6E5z -3E 
[74] https://www.tunicabiloxi.org/  
[75] https://rising.globalvoices.org/blog/2014/03/12/wikitongues -document -your -language/  
[76] https://wikitongues.org/  
[77] 
https://www.youtube.com/watch?v=u48gNyRZmlc&list=PLTULETeBko5Eqq8Jw4yT5Zh5ykTs3e2Ys&i
ndex=11  
[78] 
https://www.youtube.com/watch?v=EU 4LqdGZ9jg&list=PLTULETeBko5Eqq8Jw4yT5Zh5ykTs3e2Ys&in
dex=10  
[79] https://www.freeplayenergy.com/  75 
 [80] https://www.lifelineenergy.org/about -lifeline -energy -us/history -lifeline -energy/  
[61] https://youtube.com/playlist?list=PLTULETeBko5Eqq8Jw4yT5Zh5ykTs3e2Ys  
[61] https://youtube.com/playlist?list=PLTULETeBko5Eqq8Jw4yT5Zh5ykTs3e2Ys  76 
 11. AI & Law   
 
 
11.1. Introduction  
Nine presentations from Brazil, the United States of America, France and India explored the legal and 
regulatory domains of AI. Caroline Tauk posed the ques tion of whether an Artificial Intelligence can 
be an inventor? An example is that of the AI that designed a painting – known as “The Next 
Rembrandt ” – after having been trained on Rembrandt ’s paintings with the instructions to replicate 
them. Even art spec ialists could not clearly distinguish between Rembrandt ’s and the AI ’s styles. This 
example is indicative of AI ’s ability to not only mimic but also create new products, including works of 
art, inventions, documents etc. Due to AI ’s ever -growing ability, t he role of Intellectual Property must 
be reflected. Although there may be the systematic recognition of AI as an inventor itself, we should 
continue to be concerned about the rights of the inventor. According to Tauk, the inventor must be 
the designer, and  we should separate the inventor from the one who receives the royalties. The issue 
to be noted here is that we are trying to humanise the machine. Once machines are being humanised, 
the principle of agency comes to the fore. In essence, even if AIs can be  creators and be creative, there 
must always be a human involved.  
AI and Cyber Terrorism were the focal points of Samridhi Arora ’s presentation. She succinctly stated 
that from time immemorial man has not only endeavoured to understand life but also to cre ate life 
itself, such as with AI. AI and other emerging technologies bring with them a conundrum: they both 
promote and weaken cybersecurity. Due to the utilisation of data gathering and analytics, supported 
by natural language processing which can help st rengthen risk prediction, cyberterrorists can use the 
same skills and technologies to circumvent such protective mechanisms. To mitigate this it is 
77 
 imperative to stay protected against current and emerging threats, together with observing 
developments in e merging technologies and also to understanding how these technologies work. In 
addition to understanding how AI works, multi -stakeholder collaboration in national and international 
platforms is requisite to standardise and promote best practices and the de velopment of policy.  
AI and its governance bring together roleplayers from a broad variety of sectors, culminating in the 
intersection of law, technology and policy. It is here where Ameen Jauhar positioned his contribution 
with an overview of how AI can b e used to enhance legislative administrative efficiency in India. Jauhar 
is a proponent of the notion of predictive justice. Predictive justice protects people from bias. It was 
remarked how there is an interesting debate amongst humans questioning whether  we are 
envisioning algorithms on a higher pedestal than us? And if so, what do those responsibilities entail? 
Begin human and fallible, judges can make mistakes, but how will algorithms and the owner/designer 
of algorithms be held accountable? If we consi der the levels of patience and sympathy we accord to 
judges, will this same level be accorded to algorithms? Therefore, AI can indeed enhance legislative, 
administrative and other sectors ’ efficiency, but how will AI be held to account should something go 
wrong? Isabella Ferrari also engaged on the topic of how AI can assist with decision -making in the legal 
system. She stated that AI can be adopted to provide recommendations to judges, provide judgements 
that must be followed, and even replace human judges  in some instances. Though there may be 
concerns that arise from AI ’s embeddedness in the judiciary, we can instead ask how machine learning 
can best be utilised to improve decision -making, to account for, or alleviate, potential errors in human 
decision -making. Dan Shefet elaborated on the advantages of using AI to improve decision -making in 
the courts based on algorithms. He asked “who judges the judges ” and pointed out how human 
fallibility in court orders impacts people ’s lives when wrongful, or biased,  outcomes result from such 
pronouncements. He argued that although AI has been critiqued for being biased, it must be 
emphasised that humans are biased too. And if the processes can be improved for how data is 
collected, curated and embedded in an algorith mic data set, statistical calculations will only continue 
to improve.  
Since there may not currently be legislation in place to legally mandate the design, deployment and 
use of AI, Gary Marchant provided an overview of soft law governance of Artificial Int elligence and the 
Right to Know. He argued that one of the benefits of soft law is that it fills gaps in AI governance. Soft 
law is also a suitable avenue for the design of guidelines and policies, since it remains agile and flexible, 
and can adjust accord ing to the pace and scope of the continuous development of AI and other 
emerging technologies. This approach was supported by James Sherer who presented ethics in 
Artificial Intelligence and promoted a practical approach to presentation and defence. Most o f the 
current engagements with AI are with weak AI since this encompasses process -driven algorithms that 78 
 assist with decision -making. These are not the types that will replace or simulate humans, but they 
will assist with, and in some instances, replace hu man decision -making. These outcomes are based on 
data aggregation, curation, analysis and presentation. To promote effective regulation that will ensure 
quality and accurate information output, it is recommended that regulation be embedded throughout 
the l ifecycle of algorithm development. The benefit of the lifecycle regulation is that citizens are 
informed of what will be done, how it will be done, and what the potential outcomes will be that affect 
their daily lives. The positioning of responsibility rem ains a key concern, but at least with a phased 
approach, checks and balances are embedded from early on.  
Filipe Medon warned against the harm which AI can cause to society in his presentation on civil 
liabilities. One of the greatest concerns of AI is its opaqueness, which is compounded by its ability to 
mirror and reproduce existing biases in society. He called for more transparency of data as well as 
holding those who are responsible for designing and deploying such technologies to account. While 
on the o ne hand there is a call for the transparency of a system, Justice AK Sikri forewarned of the 
growing threats to privacy due to AI. He acknowledged that the concept of privacy is very broad and 
that it can be violated in many ways. It is due to these realit ies that there should be continuous efforts 
to protect the right to privacy. With AI products and services becoming ever more embedded in our 
daily lives, it means that we and our data become the products ourselves. It is therefore imperative to 
regulate d ata collection and management within a well -defined strategic framework.  
 
11.2. Overview of presenters  
Caroline Tauk  
Can Artificial Intelligence be an inventor?  [82]  
The presentation was opened by posing the question of whether only humans can be creative? In 
response to this, it is stated at AI can surprise us. An example is provided of how in 2016 AI mimicked 
Rembrandt ’s brush strokes and produced a painting, nearly 400 years after the artist himself! This 
painting was named “The Next Rembrandt ”. This was achieved by humans training an AI by using 
various Rembrandt paintings as references, and then the algorithm was instructed to produce a brand 
new painting replicati ng the artist ’s style.  
Due to this and other examples, Ms Tauk suggested the need to reflect on the role of Intellectual 
Property Law in the face of this new reality brought on by emerging technologies. IP Law protects by 
copyright, original work such as m usic compositions, paintings, movies and written texts. IP Law also 
protects original work by patents such as inventions, whether it be mechanical, technological or 79 
 pharmaceutical. The problem that arises is the fact that creativity is normally attributed to human 
beings, which is why legislation protects humans as authors and creators.  
The above consideration leads to a discussion on how AI interacts with humans to generate creative 
products. Machine learning as the predominant AI technology teaches a comp uter program to identify 
patterns and data and then apply the knowledge to new data and processes. Together with this, 
machine learning is the dominant technique disclosed in patents and is included in nearly 40% of 
identified inventions, according to the World Intellectual Property Organisation (WAIPO). In these 
instances, AI was used as a tool to help the inventor.  
Covid -19 has contributed to the acceleration of new methods by which AI tools create content and 
improve methods. However, this is not the cor e concern. The issue at hand is the fact that AI is 
developing innovations on its own, due to the minimal human contribution to the final output. The 
question thus arises of who owns the copyright to these creations? Machines have no rights, will it be 
the machine’s owner, the service provider, or the person who trained the machine? Currently, there 
is no correct answer. These concerns are currently being deliberated in the courts. Can an AI system 
be recognised as an inventor? In 2020 the European, America n and Australian Patent Offices denied 
the application by Stephen Thaler to name AI as the inventor of DABUS[83]. It must be noted DABUS 
does fulfil the potential ability requirements[84]. An Australian Court decided in 2021 that an AI 
system can be an inv entor and the owner of the system can also request patent protection. It must be 
noted that South Africa granted the patent to the AI (DABUS) in August 2021[85]. In conclusion, only 
time will tell whether this is the end of anthropocentrism in IP law.  
 
Samr idhi Arora  
Artificial Intelligence and Cyber Terrorism  [86]  
From time immemorial man has not only endeavoured to understand life but also to create life itself, 
such example AI. With any new technology opportunities are created, but with it also come 
conse quences. One of the side -effects of the internet is the occurrence of cyberterrorism and it is 
therefore important to reflect on solutions posed by this threat.  
Samridhi Arora stated that AI is an example of fabricated consciousness, when looking at how it  can 
be used, two disparate scenarios come to mind: 1) it promotes cybersecurity, 2) it weakens 
cybersecurity. Together with implications on cybersecurity, there is also the occurrence of 
cyberterrorism. The latter is a conflation of terrorism and online s paces, where threats and unlawful 
activities target networks, computers and digital platforms of governments, and public and private 80 
 entities. A few examples were provided of cyberterrorism and then mitigation efforts were discussed 
in which AI can help pr event cyber terrorism. For example, AI can be trained and used to detect new 
threats and malicious activities, which is a lot more effective than traditional software. AI also allows 
super predictive intelligence with natural language processing that curat es data and strengthens risk 
prediction by pinpointing potential weaknesses in one ’s existing computer system. Having this 
information enables one to plan and allocate the requisite resources to identify vulnerabilities and 
prevent potential malicious atta cks utilizing malware, hacking attempts and viruses. These actions 
essentially contribute to cyber resilience.  
She noted that to stay protected against current and emerging threats, it is important to observe 
developments in emerging technologies and also to understand how these technologies work. She 
suggested that additionally, solutions and prevention strategies must be regularly reviewed so that an 
entity does not fall behind. Together with the foregoing, regulatory frameworks are another tool in an 
entity’s arsenal to protect against cyber -threats which can be strengthened by consulting with 
industry and legal experts who can best assess current contexts and also advise on strategies going 
forward. AI frameworks should define broad principles and guidel ines, whilst organisations must 
design and cater these to the specific needs of the organisation to ensure compliance. Another 
consideration is whether AI can be acknowledged as a legal person, and if such personhood is 
conferred, it must be accompanied by  suitable insurance to protect against wrongful decision -making 
and/or actions by the AI system.  
In conclusion, these issues must be discussed on national and international fora to not only raise 
awareness and promote multi -stakeholder participation but al so to collaborate in the standardisation 
of best practices and policy development, to mitigate threats and damages that may arise. Regular 
revision of existing laws and regulations together with sectoral reform (if and when needed), will allow 
for the iden tification of weaknesses and also recommend suitable mechanisms to update laws, 
regulations and sectors in the face of emerging technologies. Therefore, both the opportunities and 
the challenges of AI need to be observed, followed closely by responsible ac tion to avoid damages.  
 
 
 
 
Ameen Jauhar  81 
 Using Artificial Intelligence to enhance legislative administrative efficiency in India  [87]  
It is interesting to note that the presentation was positioned at the intersection of law, technology 
and policy, especially insofar as it pertains to AI ethics and AI governance, as well as the integration of 
AI within legal and justice systems. Ameen Jauhar provided examples of India ’s experience in 
developing and piloting AI intervention, as well as the digitisation process, within these systems. 
Together with this, consideration was given to the cost -efficient manner in which court 
pronouncements were translated to nine different Indian vernaculars to make the rulings more 
accessible to non -English speak ing populations.  
Some key considerations pertaining to AI ’s integration in these systems, included the 1) bolstering of 
administrative efficiency, 2) the facilitation of more sophisticated automation that supplements 
judges (not to replace them), and 3) the improvement of the overall access to justice.  
She noted that India ’s current usage of AI has been starkly different from how international use cases 
have occurred. The translation tool utilised does manage to capture the unique subjectivities of the 
Indian justice system and demonstrates a thoughtful way of improving access to judicial information 
as well as justice delivery in general. In conclusion, this brief presentation provides an overview of 
how India  has been utilising AI to enhance legislative administrative efficiency.  
 
Gary Marchant  
Soft law governance of Artificial Intelligence and the Right to Know  [88]  
Gary Merchant opened his presentation by providing a definition and explanation of what soft la w 
entails. He defined it as: “Substantive obligations and requirements created by instruments that are 
not directly enforceable ”. Examples include guidelines, ethical codes, principles, private standards, 
codes of conduct, voluntary programs and partnershi p programs. These can be implemented across 
all sectors of society, but interestingly, following a study, it was found that governments are the 
foremost participant in AI soft governance.  
He recognised the benefits of soft law, one of them being that it fi lls gaps in AI governance (particularly 
if there is a lag in legislation and regulation) due to its flexibility and agility. There are however 
shortcomings inherent to soft law which inhibits its effectiveness and credibility. These pertain to who 
particip ates, how is it enforced, how are people/organisations kept to account and transparency due 
to legal disclosure not being ratified. These aspects pose challenges to the right to know. 
Notwithstanding, it is a fact that soft law is a reality and can be seen  as the preferred approach due to 82 
 the rapid growth in emerging technologies and its ability to address gaps until regulators and 
legislation fill them.  
In his presentation, reference was made to a project by the Centre for Law, Science and Innovation, 
“Soft-Law Governance of Artificial Intelligence ”[89] , at the Arizona State University (the entire 
database is available online). Following on the project, the is a recommendation to promote AI Soft 
Law version 2.0. This will:  
• Promote transparency in all ste ps of the adoption and implementation of soft law 
programmes  
• Involve trusted intermediaries  
• Provide regular public reports on achievements and limitations  
• Include direct and indirect enforcement  
He ended the presentation with a quote by Winston Churc hill, “Soft law is the worst form of 
governance, except for all the others ”. 
 
James Sherer  
Ethics in Artificial Intelligence and a Practical Approach to Presentation and Defence  [90]  
When looking at information governance or big data applications, together with the utilisation of AI, 
one engages with the domain of weak AI, or the process -driven algorithms, that assist with decision -
making. These then do not nece ssarily replace humans in the workplace, but they may replace 
individual decisions made by humans. In his presentation, James Sherer gave examples of American 
(such as the FTC), Chinese and the European Commission ’s approaches to big data and AI applicatio ns 
and resulting regulations. One can consider, for example, the GDPR with its regulations and legislation 
about privacy, and the impact it has on big data and information management.  
The foregoing raised the question of what regulatory enforcement meant? Part of the process with 
the FTC is to break down the various components of the regulation, to make it more streamlined and 
accessible to the public. Some of the components were briefly mentioned:  
• The data -gathering phase of algorithm development  
• The data compilation phase (which includes data cleansing and evaluation)  83 
 • Based on the data selection, one must then decide on which model to use, which is the next 
phase of model and A I application/tool selection  
• The following phase is disclosure, also known as the step of consent  
• Finally, the next step is model deployment which should be supported by a deployment 
strategy and regularly audited to check accuracy and correc tness  
So, throughout this lifecycle, citizens are informed of what will be done, how it will be done, the quality 
of the process has been clarified and checked, internal checks have taken place and disclosures have 
occurred, and finally, the model is being  applied. A challenge that potentially arises is the aspect of 
responsibility, for once a model is deployed, whereto does responsibility extend? Hence, Mr Sherer 
concluded that the concerns and considerations throughout the lifecycle must be built in from the 
beginning, to ensure that responsible practices can be both observed and reported on.  
 
Isabela Ferrari  
The Honorable Artificial Intelligence risks and possibilities of algorithmic decision -making in the 
Judiciary  [91]  
Technology i s reframing the way we live. This can be seen in the instances where computers and AI 
are making the decisions humans once made, and in this case specifically, within the legal domain. 
Keeping in mind the concerns that arise, the presentation by Isabela Fe rrari focused on the risks and 
possibilities of algorithmic decision -making.  
AI can be adopted to 1) provide recommendations to judges, 2) provide judgements that must be 
followed, and 3) replace human judges in some instances. Although this might be frigh tening, the 
developments and opportunities do make sense, for example insofar as those decisions may pertain 
to only proprietary rights and small amounts. Ms Ferrari gave an example of a robot judge being 
developed in Estonia to handle small claims. In suc h instances, due to the repetitiveness of these cases, 
there may not be much need for human creativity. Robot judges can foster the rule of law and values 
that are upheld in legislation, such as accessibility, efficiency, consistency, and the handling of 
backlogged cases.  
As addressed earlier, with the opportunities, come the concerns - such as the opacity of algorithms. 
Algorithms make decisions based on their ability to apply machine learning: they learn based on the 
data that has been input and therefore create their programming. The point is emphasised that 
machine learning algorithms learn by finding hidden patterns in this data following several 84 
 correlations in many layers. This means that when the output has been provided, it does not allow 
humans to f ully understand the internal process of how the algorithm got to that decision. This is also 
known as the black box of algorithms, for just looking at the code is insufficient to provide such 
decisional clarity. Hence, there is a gap between the activity o f the programmer and the behaviour – 
or outcome – of the algorithm. To address this concern, programmers are engaging in a developing 
field known as Explainable AI.  
Another concern is bias. If biased data is input to algorithms, the output will also be bia sed. Since 
humans and society are inherently biased, the patterns are replicated, targeting (or excluding) 
historically disadvantaged, vulnerable, minority and/or marginalised individuals and societies.  
In conclusion, the concerns do not only imply negativ e consequences when adopting AI in decision -
making, for the opportunities should also be considered. We should instead ask how machine learning 
can be calibrated to improve decision -making, address bias in human decision -making, and reduce 
opacity in the i nternal machine learning processes.  
 
Filipe Medon  
Civil liability and Artificial Intelligenc e [92]  
The main goal of the presentation was to demonstrate how, despite all its benefits, AI can cause severe 
harm to society. This is indic ative of why it is imperative to update the traditional civil liability schemes. 
With the proliferation of technologies, the scope of AI is also expanding, enhancing daily human 
activities such as driving and providing additional security measures such as avoiding human -caused 
accidents.  
Concerns that arise from AI include its opaqueness, ability to reproduce existing biases in society, and 
poor quality in data. To mitigate this, transparency of, and diversity in, data must be encour aged. 
Together with this, we should collaborate in promoting the ethical development and testing of AI. This 
can be achieved by encouraging regulatory sandboxes.  
AI poses risks to civil liabilities due to its complexity, autonomy, l imited explainability, unpredictability, 
and the fact that multiple actors contribute to its design. The core issues become clear now, that if 
many entities are involved throughout varies phases, who will be held liable?  
In resoluti on to the issue of liability, three core components are elaborated on, as also discussed in 
the book “Artificial Intelligence and Civil Liability ”[93] [94 . These are 1) the parties involved, 2) the 85 
 type of AI, and 3) its autonomy which may alter the risks  involved. Finally, global collaboration is of 
utmost importance.  
 
Justice AK Sikri  
Artificial Intelligence: Growing threat to privacy  [95]  
Privacy is a very important set of human rights and has authoritatively been recognised by th e 
Supreme Court of India (Justice K. S. Puttaswamy v Union of India Supreme Court case  [96]). 
Conversely, the Constitution of India does not explicitly recognise privacy as a fundamental right, but 
recently in a court case it has been identified as such, a lso since it links with Article 14 “Right to 
Equality”, Article 19 which refers to freedoms, and Article 21 which is the “Right to Life and Liberty ”. 
Justice AK Sikri acknowledged that privacy consists of various facets and likewise, can be violated in 
man y ways. In the context of AI, this right must be best protected. It is also recognised that AI is already 
embedded in many aspects of our lives. It also has the potential to improve outcomes and the delivery 
of services across various sectors of society as  well as government. What must be emphasised is the 
“National Strategy of Artificial Intelligence ” [97] (NSAI) which was released in India in 2019 by NITI 
Ayog[98]. The NSAI has attempted to bring AI into the spotlight of reform policies and to utilise 
rese arch to solve problems. The aim is therefore not only to solve national societal and industry 
concerns but also to play a global leadership role by scaling these solutions.  
The opportunities are however counterbalanced by the challenges and impacts – direc t and indirect – 
AI poses to human rights. Privacy, as mentioned earlier, is very central to the discussions on AI, since 
as a right, it has much to do with the dignity and identity of a person. As a notion, privacy is expanded 
on by defining it and refere nce is again made to the “Fundamental Right to Privacy ” case of Justice K. 
S. Puttaswamy v. Union of India[99]. What is problematic is the fact that the surveillance systems (in 
India), are being developed without effective social engagement. Together with  this, companies 
continue to feed individual and vendor data into AI systems without these stakeholders ’ consent or 
knowledge. Some problems arise such as data exploitation, identification and tracking, voice and facial 
recognition, prediction, profiling, decision -making, and the personalisation of preferences.  
In conclusion, in the era of AI, AI data does not only define us, but it also plays a role in the 
development of AI products and services targeted specifically at individuals. This means that users – 
individuals – become the product. It is imperative to regulate data collection and management within 
a defined strategic framework. It is an essential condition for an open and democratic society, as well 86 
 as individuals ’ self-fulfilment and the exercising  of freedom of expression. Therefore, a robust legal 
system is fundamental in protecting the right to privacy.  
 
Dan Shefet  
Artificial Intelligence and Justic e [100]  
Due to the enormity of this field and its implications, the focus of th is presentation was “Who judges 
the judges? ” In this presentation, Dan Shefet expanded on problems associated with the justice 
system together with examples and solutions. In particular, how AI can be incorporated into these 
solutions to assist with the ju stice system problem was recommended.  
The presumption of innocence is being heavily challenged today by social media and this tendency of 
political correctness. These two aspects have shifted the burden of proof, which is a danger to the 
presumption of inn ocence, leading to the influencing of judges. Consider for example how a judge 
may be influenced in his decision -making should there be a particular public outcry on social media 
for or against a case, even if the public does not have all the (accurate) in formation at hand? Due to 
the unpredictable nature of court cases, the notion of equality is challenged, depending on who can 
afford, and has the best access to resources, such as lawyers, finances and information. This is a threat 
to democracy and trust i n institutions, especially if biased decisions are being made.  
Subsequently, AI has been criticised for being biased together with the developers ’ role in this bias. It 
was however noted that this bias is not done so wittingly, i.e. developers do not all consciously code 
bias into their programmes. Bias and prejudice are unfortunately features of humanity. It was argued 
that in this case, AI which is based on logic, may be less biased than humans since it is 100% objective. 
This is because AI can avoid (human) statistical miscalculations which will help prevent a misca rriage 
of justice. It has been recommended to the French Ministry of Justice and the European Commission 
that AI should be included in the judicial process, in the following manners: 1) the profiling of judges, 
2) AI can be used to analyse precedent, and 3 ) it will assist with the analyses of facts and evidence.  
Artificial intelligence is being challenged for being biased, but unfortunately, the judicial system is 
biased. AI is a solution that could be applied across the board.  
 
 
References  
[82] https://youtu.be/KOvydAJ Slkg 87 
 [83] https://www.dwt.com/blogs/artificial -intelligence -law-advisor/2020/05/uspto -ai-inventorship -
ruling  
[84] https://artificialinventor.com/dabus/  
[85] https://theconversation.com/in -a-world -first-south -africa -grants -patent -to-an-artificial -
intelligen ce-system -165623  
[86] https://youtu.be/Gq3f9PDvOlI  
[87] https://youtu.be/eQ6 -8U3aQk8  
[88] https://youtu.be/Cd -Nigc_YvM  
[89] https://law.asu.edu/centers/law -science -innovation  
[90] https://youtu.be/D6weDm0qW34  
[91] https://youtu.be/LEyix4tMm0o  
[92] https:// youtu.be/C -uuP2hEHyA  
[93] https://uerj.academia.edu/FilipeMedon  
[94] https://www.migalhas.com.br/coluna/migalhas -de-responsabilidade -civil/351200/danos -
causados -por-inteligencia -artificial -e-a-reparacao -posta -a-prova  
[95] https://youtu.be/H0NMlrphLPI  
[96] 
https://indiankanoon.org/doc/127517806/?__cf_chl_jschl_tk__=pmd_TPQx6kHoEB7kP8FVlx81JFdUL
h3F3C87afp.bDF3E0s -1634136771 -0-gqNtZGzNAjujcnBszQg9  
[97] https://indiaai.gov.in/research -reports/national -strategy -for-artificial -intelligence  
[98] https://stip.oecd.org/stip/policy -initiatives/2019%2Fdata%2FpolicyInitiatives%2F24951  
[99] https://www.scobserver.in/court -case/fundamental -right -to-privacy  
[100] https://youtu.be/5iXWYe0d2is  
[81] https://youtube.com/playlist?list=PLTULETeBko5Ha -J34YqOJjTieBXJjkq80  
[81] https://youtube.com/playlist?list=PLTULETeBko5Ha -J34YqOJjTieBXJjkq80  88 
 12. AI, Big Data and Innovation  
 
12.1. Introduction  
The AI, Big Data and Innovation t hematic area explored innovative and creative ways in which AI can 
be used to streamline and improve processes across a diverse representation of sectors. Six 
presentations from the United States of America, Canada, Chile, Germany, South Africa, and Turkey  
dove into both the opportunities and challenges. Jason Mars first provided an overview of the 
transformative and disruptive implications of AI. He took us on a journey of how society developed 
across millennia and developed policies and guidelines that ac commodated, shaped and adapted to 
our intuitions of mores and folkways, values, and beliefs within societies. Our policies and 
engagements were influenced by geographic and relational proximity. There is however a 
fundamental difference between pre -interne t society and the one we experience now. Notions of 
proximity have shifted drastically, although we may be a citizen of a country, living in a specific town 
or city, we are also global citizens and connected via the internet. Information is now moulded by local 
and digital mores and beliefs, and our social fabric has also adjusted. These beliefs can be manipulated, 
and the fabric is torn, and that is why public policy is of utmost importance. Media plays a role in 
informing policy, and it must remain a chan nel, managed with integrity, to communicate and develop 
truthful and accurate information.  
Maria Paz Hermosilla expanded on the benefits of AI, especially in the public sector and argued that 
transparency needs to be prioritised. In the promotion of access  to information, an interesting point 
was raised around ‘significant transparency ’ or ‘meaningful transparency ’. This means basically that 
you do not necessarily want to make everything in  a system transparent, but only those things that 
are important for people to know. Differentiating between what is useful to know, and what is not, 
may pose a challenge for regulators, and public and private sectors. But it is agreed that if certain 
information is within the public ’s interest, they have the right to reque st and gain access.  
89 
 AI as an enabler to small business development was the theme of Melanie Stuetz ’s presentation on 
“Democratizing the knowledge of successful venture capitalists: From a “pre-flight check ” for business 
ideas to entrepreneurial thinking ”. The presentation ref lected on Melanie and her husband, Andreas ’, 
childhood dreams and experience as entrepreneurs and pilots, which inspired their current 
endeavours. The importance of a pre -flight check was highlighted – not only when flying, but also 
when planning a start -up. Brad Mostert also talked about AI in small to medium businesses. It was 
observed that the majority of developers in the space do not have a formal computer science 
background but are instead highly effective problem -solvers and must also play a variety of roles 
within their business. But with the increase in and availability of open -source software, citizens have 
more opportunities to gain access to and develop skills about developers. This can be referred to as 
the “access renaissance ”. But just because  you have access and some skills, it does not guarantee the 
best possible outcome should a machine learning algorithm be implemented, it can however provide 
a satisfactory outcome. The better -trained software developers are, the better able they will be to  
improve their understanding and reduce inaccuracies and uncertainties.  
Abhishek Gupta provided a roadmap to more sustainable Artificial Intelligence systems. If one 
understands the context of a problem, especially about AI and emerging technologies, one i s better 
positioned to develop sustainable software. The carbon impact of AI is a topic that was explored 
creatively in the presentation. Not only does this have an impact on the environment, but it brings 
with it a host of societal concerns. Four key reco mmendations were made to help guide our decisions 
and actions towards achieving an eco -socially responsible AI system.  
And finally, the macro eco -social considerations of AI and mirrored micro -human considerations of AI 
implications of brain -machine interf aces (BMI) were discussed. This was presented by Ibrahim 
Kushchu. To situate the context, a few definitions were provided to clarify the meaning of AI and BMI, 
and these were extended to the actual applications of technology interfaces between external sti muli 
and the brain. These technologies provide solutions to those who require prostheses for limbs lost, 
they provide the ability to control external machines, but conversely, they may provide the 
opportunity for free will to be influenced. If AI is used e fficiently, it can enhance our right to know.  
 
 
 
Jason Mars  
Transformative and disruptive implications of AI  [102]  90 
 Artificial Intelligence and technology, and their relationship with public policy and media were central 
themes of Jason Mars's presentation. He spoke about how these technologies impact the way we look 
at these interesting worlds and how they are connected and will evolve.  
He stated that public policy looks at the development of laws, systems and how communiti es develop. 
It captures our intuitions of mores and folkways, values and beliefs within societies. Thus, it is of much 
importance, especially in terms of having an open media, a free media, a media that is not regulated 
too much. The nature of our world is  changing because of technology and AI. AI aren ’t citizens, so we 
do not have to grapple with the notion of what happens when we make AI citizens? Currently, AI is 
instrumental to analyse data, and it is an accelerator for ways in which technologies can co ntinue to 
be created and used for innovative purposes. However, it also fundamentally changes the fabric of a 
society, what we are experiencing now is completely alien to us. Consider modern 
humanity/civilisation for the past 13000 years – we were defined by proximity and by geographic 
proximity. This defines communities pre -internet, where communities separated geographically have 
limited to no bearing on other communities, and where these granular communities develop 
themselves and their public policy app licable to their circumstances and needs. The nature of these 
granular communities was fluid and changed gradually over time. Public policy is a living thing – it is 
never complete – there is impermanence.  
He also considered the role media played in inform ing policy. It creates a channel to communicate and 
develop truth, essentially a unified notion of truth. However, fundamentally, public policy trails behind 
innovation and policy. Especially now due to the rapid growth and change in technologies. We are 
now in a massive change historically of what communities look like, due to two reasons:  
• The geographic proximity has less and less bearing on what a society is, i.e. we have 
organisations with no physical location. This means we have a blended commun ity due to the 
internet, and policy and media trail behind  
• The permanence of all activities that are expressed through digital needs is on a trajectory of 
moving into this ‘new’ social fabric. It is not the geographic fabric, but the digital fabric and 
there is a permanence herein that is changing things.  
Shows how the social fabric has changed, as can be seen in terms of social sensitivities – racial, ethnic, 
gender, religion – which shifted across time. We now need a much broader sense of what poli cies 
make sense for our current contexts. How do we acknowledge the trajectory of our social fabric from 
geographic to digital proximities and how does the permanence of media? Media will have a field day 
in modern and future politics or public platforms s uch as which celebrities have because any aspiring 91 
 journalist can go and find what politicians have said and done when they were younger – based on 
cultural sensibilities we have now.  
He conveyed that we need to catch up as to how justice needs to work and  the processes, we follow 
in developing these policies. We need to be thoughtful in terms of media on what is okay and not 
okay. We should have an expiry date as to when something was said in the past, and how it could 
potentially influence the future. AI can be used as a tool to dig up and divulge data and trends on an 
individual in the public ’s eye. We are accelerating our ability to access information on society. We 
must be thoughtful.  
 
Melanie Stuetz  
Democratizing the knowledge of successful venture capi talists: From a “pre-flight check ” for 
business ideas to entrepreneurial thinking  [103]  
At IDEASCANNER  [104]  - where business ideas are scanned – access to information is provided by 
democratising the knowledge of successful venture  capitalists. Melanie Stuetz's presentation posed 
three questions together with their responses:  
1. Why do most start -ups fail?  
a. The market hasn ’t been accurately identified, lacks insufficient funds, etc.  
2. What makes a business model successful?  
a. Natural langua ge processing and sentiment analysis provided some insight: the focus 
is essential, the solution must solve ‘pain’, the solution must save time and money, a 
moat/buffet is required to support the start -up in the long term, and finally, the 
solution must be  easy.  
3. How can you improve a business idea?  
a. Artificial intelligence must be used to foster human intelligence. With IDEASCANNER 
the application is very easy. By answering simple yes/no questions, a success 
percentage will be given to indicate business viab ility. In the course of validation, 
IDEASCANNER had a 90% corroboration.  
She provided some general statistics, such as that 137,000 start -ups were founded each day as 
compared with 120,000 start -ups that fail every day. That means is only a mere success ra te of 12%. 
She outlined that IDEASCANNER can help with this problem by utilising AI to democratise access to 92 
 successful entrepreneurs ’ knowledge. IDEASCANNER is also engaging with universities to make the 
technology more accessible to students to support p otential entrepreneurs even sooner.  
 
Abhishek Gupta  
A roadmap to more sustainable Artificial Intelligence systems  [105]  
Abhishek Gupta covered the following issues in his presentation:  
1. Societal (social inequities) and environmental (carbon output) impacts of AI  
2. The current state of carbon accounting in AI is still in a nascent stage  
3. How these issues can be solved  
He stated that an aspect one does not immediately connect with AI, is its c arbon impact. Regardless, 
it has a huge impact together with raising societal concerns. These risks can luckily be mitigated, but 
for that, carbon accounting is required to best guide our decisions and actions. The accounting part is 
important, because “we cannot fix what we cannot measure ”.  
Mr Gupta proposed four key areas: 1) better data aggregation and collection as well as research, 2) 
standardisation and measurement of different methodologies which will enable comparisons, 3) by 
mapping the needs of p ractitioners the requisite tools – code or web -based – can be designed and 
implement to improve the workflow and 4) practice which entails a strong degree of evangelism to 
normalise sustainable AI systems.  
He suggested in his closing remark that an eco -socially responsible AI system is imperative to 
contribute to sustainability because essentially, we do have the power to effect change by making 
informed decisions, sharing ideas and designing solutions that are carbon -efficient  [107].  
 
Brad Mostert  
Artificial Intelligence in small to medium business  [108]  
As opposed to speaking about inherent biases in training and/or big data sets, this presentation by 
Brad Mostert focused on how these problems come about, especially from the perspective of 
someone in the business. Ranging from local development community entities (on PHP, to engaging 
with developers from a variety of different organisations, insight has been gained into how a wide 
variety of local companies are using code and AI solutions to solve their challenges.  93 
 A key observation was made that though the majority of developers in the space do not have a formal 
computer science background, they still are highly effective problem -solvers. If you are in a small 
business, it mea ns that resources are restricted and that the staff needs to play various roles.  
One of the first takeaways is that AI is not a core business competency for these developers or their 
competencies. The other effect of these limited resources is that they wi ll seek any competitive 
advantage that can be achieved by one or two people, in a reasonable time for an achievable cost.  
So where does AI come into the story? AI has progressed significantly in the past decade. The 
improvement in terms of access to these technologies has improved. Whereby undergrads and 
workshop attendees have more instantaneous access to open -source software. Call it a type of an 
“access renaissance ”. One of the main ideas of a developer meetup is to share and discuss solutions. 
A factor that arose during the meetups pertained to technical considerations (such as the performance 
of models on unseen data, implementation rates, etc.), but upon asking those questions, the 
responses were stunted. This might be because some of the representativ es weren’t from a computer 
science background. So, when using any of the machine learning algorithms aimed at optimisation, 
you are not looking for the best solution, you are looking for a satisfactory solution. This is because 
the problems you seek to sol ve with algorithms, tend to be hard. Machine learning algorithms are 
used to make a good guess. The aim ultimately would be to achieve the highest measure of certainty.  
Next consideration is that access to the information, can better define confidence in t he results from 
algorithms, and the education to correctly choose and configure a case, is something we can do better. 
When all “insignificant ” errors in spreadsheets get added up, the cost is not insignificant. In conclusion, 
the use of machine learning i n small to medium businesses is the flame that should encourage the 
handling of certainty better.  
 
Maria Paz Hermosilla  
Algorithmic transparency in the public sector  [109]  
Data science can be used to improve people ’s lives and transform the public sector. O f specific note is 
the improvement of transparency of automated decision -making systems which include AI, but are 
not limited to AI. If these systems – albeit complex or simpler – are not implemented properly, they 
can affect human rights.  
Maria Pas Hermos illa made a reference to Chile ’s Freedom of Information Law which promotes access 
to information, where a request for information was made known as ‘significant transparency ’ or 94 
 ‘meaningful transparency ’. This means basically that you do not necessarily wa nt to make everything 
in a system transparent, but only those things that are important for people to know. These latter 
aspects include knowing what the goal of a system is, what the data is used for, what data is used or 
not used, what are the predictive  criteria if this is a predictive model, etc.? A questionnaire -based on 
these was designed and made available to different public agencies, but they found it difficult to get 
responses. This meant that barriers, to gaining access to these systems and requi red information, 
existed. Where information was available, it was not necessarily freely available, which provided yet 
another barrier. In some instances, there was copious processing of information that had to take place 
first, before sense could be made of it to answer posed questions.  
Following this, the research team reached out to the Council of Transparency which is an autonomous 
agency that has oversight over compliance with the access to information law (with access to more 
than 800 agencies dealing  with basic information). In this second process, there were positive 
responses and feedback, but they found that many agencies did not necessarily have automated 
(decision -making) information systems, but rather only digital repositories. This means there  is a 
challenge as to what is called, and what an agency understands, as an automated decision -making 
system. She gave the example of The Ada Lovelace Framework that is being used to measure the 
transparency of information across these public agencies to b etter understand the type, method, 
categorisation, and accessibility of information on these systems. Because even though the public 
agencies contain information, it does not mean the information is easily accessible by the public.  
In summary, the first ch allenge to be addressed is what is understood by an automated decision -
making system, the second is what kind of information should we have about these systems (not just 
technical, but be better understood), and thirdly, there is not much information publi cly available at 
all! 
Ibrahim Kushchu  
Implications of brain -machine interfaces (BMI) for “our right (not) to know ” [110]  
The presentation focused on these new technologies of brain -machine interfaces that use  AI, and how 
this influences the formation and processing of information  [111] as well as the new form of 
information that results from these brain -machine interfaces. It is essential to note the core definitions 
that guide this discussion. Ibrahim Kushchu defined intelligence as the “capacity to reduce uncertainty 
to adapt to changes in life situations ”. This leads to knowing to bet and having adaptive solutions to 
problems. Secondly, AI – which is difficult to define – is the “capacity of machines to reduc e 
uncertainty to adapt to changes in life situations. This should us to know better and have adaptive 95 
 solutions to problems ”. Mr Kushchu postulated two technical characteristics of AI: 1) as a data -hungry 
monster that intelligently collects relevant, relia ble, and the right amount of information and 2) as a 
gentle tailor that intelligently customises and delivers relevant, reliable, and the right amount of 
information.  
He stated that If AI is used in a good way, it can enhance our right to know. Consider fo r example 
equality in job searching, access to education, etc. Conversely, our right to know can be abused by 
using AI. For example, is information is dictated to an individual (predictive recommendations, 
targeted mis/disinformation), and information can be forced (such as manipulating brain waves to 
produce signals to the body to stimulate fear or relaxation) by using intelligent body -machine 
interfaces and interactions. There are some examples of the body -machine interfaces and 
interactions, that include : wearable devices, intelligent prostheses to replace lost limbs, and then 
finally the brain -machine interfaces – consisting of one or two -way direct communication between 
the brain and external world – influencing and exerting other behaviours (see the Ne uro-link project 
by Elon Musk). This last example can interfere with free will – which becomes an issue from 
philosophical and ethical perspectives – and experimentation on both animals and humans (see for 
example the Brain -net project).  
Many of the projec ts are funded by the United State Defence Agency (DARPA) and are done in 
collaboration with universities. The technologies resulting from the experiments 1) are mostly non -
intrusive brain interfaces, 2) can read and write to the brain and 3) can control ex ternal machines.  
What are the implications in terms of access and our right to know? For the former, it is no longer just 
information as text/image/video, but also involves signals to and from the brain. The source, medium 
and target of the information are  also changing. In terms of the latter, forced information can be 
designed using AI and when implemented, can lead to involuntary behaviour going contrary to the 
notion of free will. This also makes our right to not receive information very critically.  
 
References  
[102] https://youtu.be/moo4zostMk0  
[103] https://youtu.be/g2J1F7Fi_ak  
[104] https://www.ideascanner.com/  
[105] https://youtu.be/t6LGZ0xeGVs  
[106] https://montrealethics.ai/state/  96 
 [107] https://devblogs.microsoft.com/sustainable -software/the -current -state -of-affairs -and-a-
roadmap -for-effective -carbon -accounting -tooling -in-ai/?WT.mc_id=green -30456 -cxa 
[108] https://youtu.be/tP8IsvcBGfI  
[109] https://youtu.be/FEQcr4eFlBo  
[110] https:/ /youtu.be/5hDb3rGgKvc  
[111] https://thenextminds.com/  
[101] https://youtube.com/playlist?list=PLTULETeBko5G9NshDuSZcmMQE_BzyVasP  
[101] https://youtube.com/playlist?list=PLTULETeBko5G9NshDuSZcmMQE_BzyVasP  97 
 13. AI and Creativity  
 
13.1. Introduction  
Five presentations from the United States of America, Canada, Jamaica, and Israel dealt with the 
creative scope of AI and the endless possibilities it contains to visualise the design, compose music 
and test our boundaries of comedy and woke culture.  
Gene Kog an gave us insight into his childhood where he enjoyed playing video games and how this 
inspired his interest in artificial artistry. The artificial artist concept explored notions of personhood 
and agency in AI, as well as experiments with computational a gents that mimic life. He listed a few 
properties of what can be deemed an autonomous artificial artist, which included autonomy, 
originality and uniqueness.  
In Colin Clark ’s presentation, he referred to the Inclusive Research Design Centre where they work  to 
ensure that emerging policies, systems, and design practices are inclusive of the full range of human 
diversity and cultural participation. It is lamentable that even though there are efforts to promote 
inclusivity, there are still instances of discrim inatory decisions made by automated systems. Minority 
groups – due to limited data – will also be represented less in data sets which contributes to them 
being seen as outliers by the algorithms and machine learning training regimes. A call was made for 
policies and regulations to ensure the inclusion of minority groups and culturally diverse communities.  
98 
 Can algorithms be creative? This was the question posed by Galit Wellner. She extended this question 
by pondering whether they may even have imagination. What does imagination even mean? Ms Galit 
took us back to the philosophical theories on imagination by Immanuel Kant and postulated that 
imagination is a bridge between my perception and my understanding. She then queried what 
creativity means, and grounde d it in notions of novelty, value and surprise. It seems possible that AI 
can indeed be creative, and that a model – operated by a human and content generated by an AI – 
may be feasible, especially if AI and humans collaborate. In this instance, we can see  how technology 
shapes us and create value, whilst we shape valuable technologies.  
These instances of human and AI co -creation of artistic work were put on display by Suzanne Ciani 
when she expounded on music, composition and Artificial Intelligence. Ms Ci ani was a speaker at the 
very first TED Conference in 1984. Mandelbrot – who was talking about fractals – was at this 
conference too, and she was struck by the simplicity – for we all strive for simplicity in our solutions – 
of a crystalline description of  complexity. Ciani provided a demonstration of the instrument, Buchla 
200e, which is a machine that uses repetition to create music. A couple of patterns were showcased 
to illustrate the parameters of sound and complexity as performed by modular electronic  music 
instruments.  
Trudy Bell acted out two scenarios regarding the current realities on personal data collection, de -
anonymisation, as well as the monitoring of communication to ensure political correctness. Through 
these skits, the (alarming) absurditie s of these issues were highlighted, but they also inspired us to 
take an objective look at ourselves and find some humour amidst all these serious considerations. AI 
and the internet are tools that make our lives more efficient but also more complex. Essen tially, it is 
our responsibility to manage how we interact and react to AI.  
 
13.2. Overview of presenters  
Gene Kogan, Artist  
Artificial Intelligence and Creative Intelligence  [113]  
Gene Kogan introduced the Abraham project while reflecting o n his childhood where he enjoyed 
playing video games and running simulation tournaments where the AI played against each other. He 
described how this inspired his work and interest in AI -generated art. Seeking to find the aesthetics of 
neural networks, pro duced a piece of work “A Book from the Skye ” in 2015, applying DC yen to making 
Chinese handwriting using a data set of handwritten characters. He stated how interesting it was to 
explore the capacity to generate images that came from an actual data set, l earn Chinese handwriting 99 
 and use techniques such as deep dream and neural style transfer to make interesting graphics and 
animations, some of which seem like infinite loops. This can also be applied to Google Maps – zooming 
into locations.  
Moreover, he def ined the concept of the artificial artist. The concept stems from the 1980s (Harold 
Cohen), who endeavoured to build a robot called Aaron. This was probably one of the first attempts 
to flirt with the notion of personhood and agency of AI. Though there has  been lots of experimenting 
with computational agents mimicking life, Mr Kogen also noted that the limitations of AI Artists include 
the fact that in all AI artists so far, a programmer writes an art generator. This leads to the artist merely 
speaking thro ugh the programmer. Thus, AI artists end up acting like a tool and lack agency. Attempts 
have been made to address this, such as the ArtDAO idea (2016), pioneered by Trent McConaghy and 
Simon de la Rouviere which entails the ability to:  
• Create generative art and make multiple editions  
• Timestamp on blockchain  
• Sell them on Getty/Shoppify/OpenBazaar  
• Transfer rights to buyers  
• Pay for computation from proceeds  
 
Mr Kogan described other multifaceted projects such as ArtDAO -line and Abraham, proposed by him  
[114] – which have emerged intending to create an autonomous artificial artist construct - having 
autonomy, originality and uniqueness - that produces unique digit al art. Its motivations include:  
• Create artificial life  
• Interesting in modelling and exploring collective intelligence  
• Advance more general causes  
o Decentralisation  
o Security and privacy  
o Fairer economic models  
He concluded that the idea is to use  crowdsourcing to group -curate an AI -generative model and help 
with gaining autonomy. There is intelligence in groups – such as ants, bees, and termites – and this 100 
 also applies to human beings. He concluded that to model the collective imagination is proba bly his 
greatest interest.  
 
Colin Clark  
Decisions of our own  [115]  
Colin Clark started by describing his role at the IRDC  [116] [117]. He talked about his work which was 
to ensure that emerging policies, systems, and design practices are inclusive of the full range of human 
diversity, thus promoting cultural participation and creative expression for all.  
AI systems are predicated upon an emerging weave of proprietary hardware, software and data that 
are both local and remote. Increasin gly we cannot separate the servers that host the cloud services of 
technology companies such as Google, Meta etc, from the specialised hardware chips that run inside 
our mobile devices. Combining this with the vast and unprecedented troves of personal data  required 
to train a system to generate results, AI can only be developed by becoming dependent on these stacks 
of these technologies and data sets. Material infrastructure together with free -market capitalisation, 
which comes at the cost of eroding workin g conditions, are underpinned by the invisible human 
warehouses and labour that also make this possible. All of these aspects are involved when the term 
artificial intelligence is used.  
He referred to the Platform ’s culture of inevitability and wished to h ighlight the sense in which AI 
systems embody platform logic, that results from the way technology is designed by tech companies, 
specifically from Silicon Valley. He argued that these are increasingly at odds with values of equity, fair 
work, and social j ustice. Unfortunately, the way the technologies are developed and connected with 
the ideologies of progress and innovation, platform and the language of AI and ML drives a culture of 
inevitability. This culture of inevitability means that these technologie s will be deployed whether we 
want to engage with them. This is the notion of “progress”, and we cannot say “no”, because these 
technologies are merely seen as tools. It is therefore up to us to ensure they are used more responsibly 
and ethically.  
He state d that they have found increasingly the instance of discriminatory decisions made by 
automated systems, even though there is a proliferation of data. Data gathering and machine learning 
training methods must be more representative of communities impacted b y the consequences of such 
biased decision -making. The issue with representativeness is the fact that minority groups – such as 
people with disabilities – will always be considered outliers due to the algorithms and machine 
learning training regimes. Outli ers will inevitably either be recategorised or even excluded from the 101 
 data analyses. Uniqueness and difference are a kind of error in the representation of data. Refers to 
the term “new gym code ” whereby technologies disproportionally target black, immigra nt and 
racialised communities as all -inclusive subjects and thus suspects in a data regime of criminalisation. 
We need the option of being excluded.  
We need policies and legislation that ensure that the platform companies and developers of AI 
technologies are accountable for the decisions, both by design or unintended, especially to include 
the voices of minority groups and perspectives of diverse communities. A deeper form of 
representation is also needed, in decision -making, this includes ownership and go vernance of the 
platform technologies. Luckily there are successful models of collective governance, that include multi 
stakeholder groups which work together in designing cooperative platform technology alternatives. 
New ways that are fairer, democratic a nd more inclusive. There is a project known as Cooperative 
Data Communities ” that work to address the systemic inequity of AI and data platform. One of the 
partners is the “self-Employed Women ’s Association in India ”, which is the largest women -owned 
coope rative in the world and has more than 1.5 million women -worker -owners. They both grow and 
govern their initiatives, and also contribute to their communities on grass -root levels. The project is 
developing a toolkit of community -led design practices and coo perative governance approaches, 
sustainable business models and case - studies. Open -source tools are also being developed. We have 
learned to design with communities, as described in the community co -designed toolkit. What we 
make, is indivisible from how we make it and with whom.  
Therefore, individual benefits must be balanced with growing healthy and sustainable communities. 
More reciprocal alternatives, to modern platforms, must be created.  
 
Galit Wellner  
Can algorithms be creative  [118]  
Galit Wellner led her presentation with the question "Can AI be creative, and do they have 
imagination?" She noted that until recently this notion was deemed to be unimaginable, akin to 
science fiction. However, this had changed, as with the example of  the “Portrait of Edmond Bellamy ” 
that was sold for $432,000 -00 by Christies. The portrait was created by an algorithm and it was not 
the only example of an algorithm that has managed to be creative and develop works of art.  
She referred to Immanuel Kant w ho defined what we believe imagination is. Kant said:  102 
 • Imagination is the faculty of representing an object even without its presence in intuition ” – 
for example imagining virtual conference presenters due to Covid -19 impeding physical 
collaboration;  
• Imagination works by and through a “synthesis of intuitions according to categories ”; 
• Imagination first “conjoins the manifold of intuition ” and then performs on that manifold a 
“schematism ” of concepts ”, for example looking at the clouds and seeing images  of animals. 
These are concepts that we hold in our minds;  
• The schema is like a common denominator for a certain group of images  
She stated that imagination is a bridge between one's perception and one's understanding. Schema is 
foundational because we c annot experience the world without them. However, on considering 
algorithms, it can distinguish between very similar -looking objects, even though they are completely 
different (an example is provided of a ginger cat and an ice -cream sundae with caramel sau ce). Thus, 
these algorithms are doing exactly what Kant is telling us. She argued that we have assumed 
imagination is unique to human beings, but the algorithms are doing the same.  
So, what is creativity? Margaret Boden defines creativity along the three l ines of novelty, value (also 
related to understanding, and we need humans for understanding), and surprise. These three 
elements help us understand what algorithmic creativity is.  
This leads to a layered model, which composes layers of imagination and crea tivity. Each layer is under 
the responsibility of either humans or algorithms. Ms Wellner developed her theory of imagination 
based on the layered model – for which an AI still need a human operator. It is composed of three 
basic elements:  
• Starting the p roject  
o Defining the algebraic formula  
o Dedicating financial resources  
o Securing the needed computing power (servers, storage …) 
 
• Data collection phase  
o Selecting content types, collecting data from multiple resources into a dataset 
(consider the verb to create)  103 
  
• Meaning generation  
o There are attempts to teach algorithms to extract meaning  
o In textual databases, meaning can be “understood ” by AI algor ithms via vectors of 
words with which they calculate word proximity  
 
However, sometimes the meaning can be inaccurate. Since algorithms can be inaccurate, why human 
operators are still required to develop the values.  
The model, therefore, states that huma ns and AI work in collaboration: humans come up with new 
ideas and AI combines and generates the content. This essentially leads to a collaborative and co -
shaping model whereby humans and technology shape each other, but humans always remain 
involved.  
 
Suza nne Ciani  
 Music, composition and Artificial Intelligence  [119]  
Suzanne Ciani's presentation focused on the use of randomness in performance practice with the 
(Don) Buchla analogue music modular instrument  [120]. With a background in  classical music and 
extensive tertiary education, Ms. Ciani experienced the concept of electronic music and its 
possibilities, from then onwards she knew this will be her expression. Her relationship with the 
machine was one of interacting with it live. I t is interesting to note that with this machine, all of its 
data (spatial positioning, voltage, connections, etc.) were transmitted by LEDs. To this day, it is an 
element lacking in the instrument design of analogue modules. She described how on her journe y to 
New York and in her career as a musician/artist playing the Buchla, she met an agent, who 
recommended she receive additional training for them to communicate. This led her to find that she 
was in love with a machine. The denouement of this training/ex perience was that people are in fact 
machines and that we just need to understand each other ’s operating systems ,for us to communicate 
better.  
She stated that when she performs now, she is aware of techniques that are needed to enh ance the 
capabilities of the machine. As with other machines, these machines are adept at repetition. 
Randomness is not chaos, it is not out of control. With the Buchla, one can be very specific with the 104 
 randomness, due to the parameters one can put in pla ce to refine the content. Ms. Ciani closed her 
speech with a very interesting demonstration of the Buchla 200e, where she showed a couple of 
patterns of randomness.  
In conclusion, the use of randomness in a very judicial way, is a huge enhancement to the live 
performance of modular electronic music instruments. Anything that is voltage controllable – basically 
all parameters of sound – can be manipulated with a degree of randomness. This is an important 
technique to give an expansion of what the machine ca n give back to us.  
 
Comedy  [121]  
Trudy Bell  
The presentation was warmly opened by a reference to the importance of humour.  A ‘simulated ’ 
news broadcast was played, where the topic was AI and privacy and whether the government was 
doing enough to regulate how AI utilises peop le’s information.  
This led to a feature of a lady visiting a doctor who seemed to have the wrong pre -diagnosis. However, 
the doctor already knew what was going on, since “once you visit one doctor, all doctors have access 
to your information ”.The patient was shown to be shocked. She immediately raised her concerns 
about ethical issues and legal implications. The doctor then continued to divulge other personal 
information about the patient – such as her vehicle that had recently been seized due to non -payme nt. 
We returned to the simulated news broadcast, where the reporter asked, “How far is too far when 
compromising peoples ’ privacy and trust ”? 
The next skit featured a woman presenting a live vlog on her line of “Candy” products in d ifferent fruit 
flavours. Whilst busy arguing that strawberry is not a good flavour, she gets flagged by an AI persona 
for making a politically incorrect statement: “Strawberry is the worst flavour ”. Although her opinion, 
she is reprimanded because some peo ple find it offensive. The AI argues that opinions are not factual 
and may entail misinformation. Whilst continuing her argument in support of her freedom of 
expression, she is muted by the AI, since she agreed to the platform ’s T&Cs. The skit was a 
discon certing reminder of the movie Minority Report . 
Trudy Bell through the short recording – utilising the example of strawberries and the reality of data 
collection and de -identification – showcased the potential absurdity, and the impl ications, of a data -
driven society. One is starkly reminded of the tensions between freedom of expression, cancel culture 105 
 and hate speech, as well as one ’s right to access information but also protecting one ’s personal 
information.  
 
References  
[114] https://www.abraha m.ai/  
[113] https://youtu.be/HdCYOuh0UoI  
[115] https://youtu.be/QV33hcsooyY  
[116] https://inclusivedesign.ca/research/ocadu/  
[117] https://idrc.ocadu.ca/about/  
[118] https://youtu.be/l2 -6lxcAUDs  
[119] https://youtu.be/bS3gvgMxVDg  
[120] https://en.wikipedia .org/wiki/Suzanne_Ciani  
[121] https://youtu.be/yXjpp6POJRk  
[112] https://youtube.com/playlist?list=PLTULETeBko5E196Oy8Ppj2sjdLFVESqSr  
[112] https://youtube.com/playlist?list=PLTULETeBko5E196Oy8Ppj2sjdLFVESqSr  
 
 106 
 14. Youth in AI  
 
14.1. Introduction  
These six presentations were made by youth from the United States of America, Jamaica, South Africa, 
and India, on various topics regardin g AI.  
Tyler Jaynes raised the question of Algorithmic Personhood and Being. How do we measure the digital 
world to secure future inalienable rights? Towards answering this, Jaynes turned to science fiction to 
explore these emerging technologies and how t hey informed the way we perceived and engaged with 
society. If engineers take inspiration from science fiction, why cannot researchers also take inspiration 
from it? It was argued that if we only focus on AI, we miss out on the opportunity to capture and 
engage with other emerging technologies, such as nanotechnology. The presentation comes to a firm 
conclusion that we need to collaborate on definitions and terminology to avoid miscommunication.  
Joshua Burgess prioritised openness and inclusivity for disabl ed communities in a new era. In this 
thoughtful presentation, four key areas are set out for contemplation, the value and importance of AI 
for disabled persons, a discussion of AI tools that facilitate independent living, addressing bias and 
ethics in the development of AI technologies, and encouraging a multi -stakeholder approach for 
increased inclusiveness. Referring to the WHO statistics on people living with disabilities, specifically, 
the blind, Burgess argues that AI can potentially break down barrier s and increase accessibility.  
107 
 Centring the focus on Artificial Intelligence, health and law, Ms Pia -Milan Green provided a snapshot 
of emerging legal issues. It is emphasised that the Covid -19 pandemic has accelerated the integration 
of AI technologies in the healthcare industry. Together with this acceleration towards improving 
service delivery and solutions to challenges Covid -19 pose, several concerns also arise. These pertain 
to physician liability, informed consent, privacy issues and big data liabilit y. Ms Green stated that 
liability in healthcare will be influenced by the Explainability, transparency and predictability of AI 
systems and explained that discourses on agency and responsibility need to be prioritised.  
Mukund Trivedi commenced the presenta tion with a personal reflection on design theory. About the 
amalgamation of AI and design and its application in the fields of healthcare and natural resources, 
Mr Trivedi argued that the process of design needs to be simplified. When AI is used to achieve  
simplicity, the technologies and their solutions will become more accessible, especially for people with 
disabilities. In addition to this, Trivedi introduces the concept that where there is water, there is 
literacy. Improving access to water will inadver tently improve access to education. AI can therefore 
be utilised to measure the contamination in water systems, treatment plants and sanitisation systems. 
It can also best recommend solutions for improving water service delivery and the treatment of such 
contaminants.  
The need for water provision and literacy awareness is compounded by the absolute need for ICT 
infrastructure, especially in developing nations. This was the call made by Ufulu Martha -Junior Chisale 
who focused on the role telecommunications s ervice providers play in ensuring people have access to 
affordable and functional communications networks. It was argued that both public and private sector 
organisations are confronted with ongoing pressures to streamline activities, nurture innovation, 
advance efficiency and achieve demanding organisational objectives through effective 
communication. Essentially this is their duty to citizens to ensure that basic needs are met, such as the 
payments of grants and programmes to distribute Covid -19 vaccinati ons.  
Daricia Wilkinson prioritised the concept of safety and what it means to be safe. Her presentation was 
on an integrated human -centred approach to online safety. In a study conducted in the Caribbean, it 
was found that a large proportion of the respond ents have experienced some form of online 
harassment and victimisation. To address these concerns, equitable design, on - and offline 
deliberations and the promotion of justice must be central to the solution of how harm can be 
detected by AI. Wilkinson arg ued that despite the limitations AI pose, it can be harnessed to be an 
effective tool to promote online safety.  
 108 
 14.2. Overview of presenters  
Tyler Jaynes  
The Question of Algorithmic Personhood and Being: Measuring the digital world to secure future 
inalienable r ights  [123]  
Tyler Jaynes introduced his speech by questioning "How do emerging technologies impact society?" 
He stated that the impact was visible with digital technology, where everything was internet -based 
and suggested that we sho uld work towards developing a common definition to measure virtual 
environments to set the stage for the granting of rights to AI systems and non -humans, or advanced -
human entities. Even though many of these considerations were not immediately relevant, as  seen in 
sci-fi movies, it was important to start discerning potential challenges, benefits, and solutions in 
advance.  
In his presentation, Mr Jaynes questioned the nature of the virtual property. He questioned how it 
would be defined and determined. Was a n IP address only attributed to a single person in the sense 
of the design of a digital profile of individuals? How would we differentiate between information 
across different media (would the platform or method impact the content, style or structure of 
information conveyed?), and how would we go about accurately distinguishing between public and 
private information?  
Inspired by science fiction, he stated that these emerging technologies inform the way we perceive 
and engage with society. Virtual and augmen ted societies take a variety of different forms, which may 
confuse our understanding of their nature, as well as our potential engagements with fellow human 
beings. However, in this regard science, fiction guides us on how to approach, engage with and 
regu late emerging technologies. He recommended that we find virtual measures that can be 
compared with physical measures, such as physical property versus intellectual property, electronic 
property, encrypted information, and public and private information and  realise a merger between 
virtual and physical spaces where the two become intertwined. Therefore, there will be no separation 
between physical and virtual spaces. He believes this calls upon a paradigm shift that will accelerate 
the need to develop online  hubs for our digital identities, increasing efforts to justify the right to be 
forgotten, promoting legislation that supports privacy and digital property using cybersecurity 
regulations, and adopting universal means that grants legal authority to digital  property ownership.  
 
 
 109 
 Joshua Burgess  
Openness and Inclusivity for Disabled Communities in a New Era  [124]  
The presentation reflected on the experience of someone who is both blind and has had chronic 
hearing loss since birth. There w ere four key focus areas in the presentation:  
• The value and importance of AI for disabled persons, specifically the blind  
• Some of the AI tools that facilitate independent living  
• Bias and ethics concerns, in the development of AI technologies, and how  that 
intersects with data collection, privacy and the risk of marginalisation  
• The importance of a multi -stakeholder approach for increased inclusiveness in 
developing a framework for AI in the Caribbean  
He referred to WHO's statistics and said that appr oximately 2.2 billion people were living with vision 
impairment; about 1 billion were living with a disability. According to the International Agency for the 
Prevention of Blindness, up to 20 countries accounted for 77% of visual impairments (2.7% are from  
the Caribbean). Why was this important? In a society where computer algorithms were informing 
decisions, the increased prevalence in the disabled community whose interests may be excluded, 
could not be ignored. With a lack of access and affordability, peo ple with disabilities would feel left 
behind. Access to these tools was critical especially since it could enhance adaptability, especially as 
compared with able colleagues.  
However, Mr Burgess also raised concerns as to how AI may perpetuate disparities amongst disabled 
communities and the issues of bias, ethics, data collection, privacy and the risk of marginalisation. 
Marginalisation has always been a reality for people wit h disabilities, be it regarding education, 
inaccessible physical infrastructure, discrimination, social ignorance and lack of empathy. AI could 
potentially break down these barriers. Hard questions were posed:  
• Does AI technology in its present form, run the risk of increasing marginalisation for disabled 
communities?  
• Who was monitoring this? Technologies companies were currently in the lead, so what was 
the role of governments? Many modern technologies were not designed with disabled 
communities in mind . 
Mr Burgess concluded that AI mimicked a world view of normative behaviour, and its promise to 
integrate disabled communities into the normal, was in itself a discriminatory statement. This was a 110 
 human rights situation, and everyone deserved equal access an d opportunities. Therefore, in a 
multistakeholder approach, values, ethics, human rights and affordability should be placed at the core 
of AI development. Legislative frameworks must be developed that would prevent the widening the 
inequity. A final questi on was posed: AI is the future, but for whom?  
 
Pia-Milan Green  
Artificial Intelligence, Health and Law: A snapshot of Emerging Legal Issues  [125]  
Covid -19 pandemic has accelerated the integration of AI technologies in the healthcare industry, as 
can be seen for example, in remote medical consultations, patient management, resource allocation, 
image analyses and robotic surgery, etc. Pia -Milan Green noted that although these AI -mediated 
interventions were both necessary and helpful, th ey also brought along with them several legal issues. 
These included:  
• Physician liability in the digital age (informed consent liability), which was closely related to 
medical malpractice. What were the implications on physicians ’ standard of care and du ty, 
and to what extent did the physician ’s responsibility extend to AI system recommendations, 
analyses and assessments (i.e. did the role of a physician conflate with that of a ‘big data 
scientist’?). What would a physician need to do to reject the allure  of technological 
dependency?  
• Privacy issues and big data liability, especially insofar it extended to medical and personal data 
of patients and their health information. Healthcare custodians must de -identify patients ’ 
information. Unfortunately, AI tec hnology could re -identify data by making correlations 
between different data sets (data collected from health trackers, internet searchers, third -
party services providers, etc.)  
Ms Green concluded that liability in healthcare would be influenced by the Exp lainability, transparency 
and predictability of AI systems. Thus, ethical principles must be applied to the design, implementation 
and use of AI to mitigate harm to patients.  
 
 
 
 111 
 Mukund Trivedi  
 Amalgamation of AI and Design and its application in the fields o f healthcare and natural resources  
[126]  
Mukund Trivedi asked, “What does design mean to me? ” Understanding a problem and working 
towards a solution, was much like the clay that needs to be chiselled which leads to the design. But, 
the process of designing would have to be simplified. When an idea was simplified, it was accompanied 
by the evolution of human intellect. The gist of the design was when it was in its simplest form, devoid 
of all its complexities. Thus, he stated that it was necessary to focus on thought and emotion, instead 
of technicalities.  
Mr Trivedi said that man must utilise tools to reach this stage of simplicity, such as vacuum cleaners. 
We were harnessing AI to achieve simplicity. AI could give the independence th at people with 
disabilities may require. AI that utilised lip -reading could help people with hearing impairments. There 
was a huge amount of benefit in AI which was not yet being accessed to its full potential by people 
with disabilities, but as these tech nologies continued to be developed, many would be able to reach 
their potential. He held therefore that design was the interface and AI the tool to amalgamate the 
problem with the solution.  
He concluded that water was at the core of human society and was c ritical for socio -economic 
development. Hence, where there was water, there was literacy. According to WHO, 1 out of 3 people 
did not have access to drinkable water, and more than half of the world did not have access to 
sanitisation systems. AI could esti mate the contamination in water to improve the efficiency of 
treatment plants. Thus, AI and design could streamline the usage of water in agriculture, as well as 
water meters to monitor wastage in suburban areas.  
 
Ufulu Martha -Junior Chisale  
AI and ICTs in a developing nation  [127]  
Ufulu Martha -Junior Chisale's presentation was pertaining to telecommunications. She defined 
telecommunications as the study of interacting or communicating over a distance through the means 
of data, telep hone, social media and or radio. Over the years the way communication is transmitted 
from one person to the next has changed. Having a strongly established regulatory framework in a 
country promotes economic growth and alleviates poverty. Connected to such  telecommunications 
networks and frameworks, access is also central.  112 
 She established that in general, access to technology and telecommunications, both grant 
opportunities. Hence, it is essential to implement policies that look at the inclusion of all peop le and 
eliminate barriers such as the digital divide. This can be achieved by making available and accessible, 
opportunities to communicate, especially via the internet. With this increased networked mobility 
through ICTs, new opportunities have been creat ed, albeit socially, personally, or professionally.  
With these advantages also come challenges. The public and private sector organisations are 
confronted with ongoing pressures to streamline activities, nurture innovation, advance efficiency and 
achieve d emanding organisational objectives through effective communication.  
It was noted that Artificial Intelligence also plays a role in the effectiveness of ICTs and the ability of a 
country to deliver services to its citizens. We can see how AI has the potenti al to reduce labour and 
transactional costs. In addition, it increases productivity and information flow in the economies of 
resource -constrained developing countries. This can be seen for example in the manner it helps to 
overcome logistical bottlenecks a nd corruption in supply -chain management and administrative 
processes about – for example in South Africa – pension payments, grant payments, and even Covid -
19 vaccinations. By utilising ICTs effectively, a state assists with creating environments for furt her 
development across all sectors of society.  
In way of concluding, she quoted Ndidi Okonkwo Nwuneli: “For there to be effective change, let us 
disrupt and redesign ”. In essence, for there to be an effective sustainable change, we need to disrupt 
current processes and how things are done and redesign a new way of achieving our goals.  
 
Daricia Wilkinson  
Pushing Forward: An Integrated Human -centered Approach to Online Safety  [128]  
Billions of people worldwide are connected to social med ia, with most of our lives migrating to online 
spaces. Together with this, we are exposed to risks, such as privacy and harassment. Many of this 
online harm can spill into physical spaces. Consequences for individuals include self -censorship and 
the withdr awal from online communities where people ’s behaviour is influenced. In her presentation, 
Daricia Wilkinson posed the question “What does it mean to be safe? ”. 
She defined Safety to consist of the following elements, namely:  
• Privacy  
• Security  113 
 • Wellbeing  
She noted that safety concerns in the Caribbean were expanded based on the above -mentioned 
elements to conduct a study in which 551 individuals participated to gauge their experiences of threats 
in some form or another. An alarming rate of peop le reported that they had experienced victimisation 
of some sort:  
• Privacy – 43%  
• Harassment – 35%  
• Online -to-Offline – 32% (this included discrimination and online/real -life stalking)  
• Security – 30%  
With reference to the study, she concluded that int erestingly, the majority of people reported threats 
via online advertisements (325 out of 551) and that people had not experienced only one type of 
harm, but multiple ones.  
She recommended a Road to Safety which consisted of:  
• Equitable design  
• New appro aches to Justice  
• Offline protections  
  
How could the harm be detected by using automated approaches? These processes included:  
• Machine learning and Natural Language Processing 9NLP)  
• Detecting “Intentional Annoyance ” 
• Use contextual and semantic info rmation for the detection  
• API for Machine learning to assign toxicity score  
 
Ms Wilkinson held that unfortunately, the above had some limitations, such as how it could be easily 
outmanoeuvred by slight modifications, the requirement of users to flag con tent, unfair applications 
or usage of the process and the lack of understanding or consideration of social nuances. Diversity 
was a core requirement, not only of experience but also of cultural and socio -economic circumstances. 114 
 These enabled the holistic u nderstanding of how tools were affected by cultural values and social 
nuances and the integration of traditional experience.  
Contextual awareness was one of the recommendations to attend to these concerns. It encouraged 
awareness and consideration of indiv iduals’ attitudes, culture and resources for the development and 
exploration of resolutions. The scope of justice could also be expanded, such as including communities 
and marginalised societies that were usually not considered in the design, use and imple mentation of 
ICTs. Implementing such safeguards would ensure inclusivity, freedom of expression, transparency, 
and the provision of autonomy in dismissing threats. People should know their rights!  
Ms Wilkinson recommended that people (users, academics and practitioners), should understand 
online misbehaviours, know which safety tools were at hand to mitigate such misbehaviours and work 
collaboratively to design local, regional, and global guidelines and policies.  
 
References  
[123] https://youtu.be/XZPwfK2Of9Y  
[124] https://youtu.be/l1wbK53ZgZQ  
[125] https://youtu.be/XI8PGq --jT8 
[126] https://youtu.be/_rvoPDheG1Y  
[127] https://youtu.be/DrVr0BQtcmI  
[128] https://youtu.be/DKRAYQEDZ08  
[122] https://youtube.com/playlist?list=PLTULETeBko5GmQFKL2wqRydmFiojd_dOl  
[122] https://youtube.com/playlist?list=PLTULETeBko5GmQFKL2wqRydmFiojd_dOl  115 
 15. Accessibility Pavilion  
 
15.1. Introduction  
The pavilion took place in the main conference hall, during which all participants were invited to 
attend and engage with the two presenters. Colton Bishop demonstrated the Google Camswitch and 
Monica Desai delivered a Meta Accessibility De monstration. During these demonstrations, and 
subsequently, in the Question -and-Answer session, Mr Andries van Niekerk provided real -life sign 
language interpretation.  
 
15.2. Overview  
Colton Bishop  
Google Camswitch Demonstration  [130]  
When  trying to drive accessibility innovation, there are needs and gaps of different user groups. How 
to better understand these groups and address their needs are central to any process of innovation 
that will drive accessibility. The cam -switches are an exci ting project which has been in development 
for over 1.5 years. There are 50 people on the team that worked on this project 20% were volunteers, 
so much of the project was informed and inspired by volunteers.  
Apart from the Camswitch, there are other improv ements made to existing technologies, such as 
switch access, more support for users with impairments, such as arthritis, issues with repeated touch 
116 
 or painful touch, touch, switch access and voice, etc., in an attempt to reach moderately impaired 
people. I n terms of privacy, Google Camswitch is working with accessibility services, for we assume 
everyone using these services has disabilities, so there is a lot more sensitivity for their privacy, health 
data and physical data (like following a face for facial  expression recognition). The gestures are used 
in the moment but then discarded immediately after.  
Digital literacy initiatives are promoted by Google Camswitch as well. There has been a push to make 
sure the entire writing and configurations of all apps are more readable, technical, etc, feature 
sensitivity customisation: bigger and smaller gestures to make it more intuitive and more 
understandable, such that anyone can use it. There are also incentives to support conferences and 
attend as many as possibl e to understand what the standards are. With the latest updates of Switch 
accessibility on Google, it will be available for download on every Android phone and most devices 
and versions. On new Android devices, Camswitch will come preinstalled on all phone s across the 
board going forward on almost all android devices.  
 
Monica Desai  
Meta Accessibility Demonstration  [131]  
Meta is investing much in improving accessibility. Towards achieving this they seek to get constant 
feedback and then invest significantly to improve on gaps. There are multiple rounds of testing the 
prototypes which help in getting sentiment from users based on their experiences. In addition, Meta 
treats privacy as a core consideration throughout all its projects.  
The AR/VR capabilities of  Meta are intriguing, especially because they are producing Oculus at Meta. 
This extended reality – AR, VR Mixed Reality – is a new and emerging technology, that is always 
evolving. Meta is trying to work best to provide inclusive experiences because many technologies that 
are needed do not exist yet. Therefore, Meta tries to work with the disability communities, together 
with collaborating in partnership with developers to address the needs of people with disabilities. For 
example, having industry best pra ctices for XR to help guide developers to create more accessible VR 
apps such as the June release of Oculus v30, which will make this technology a better experience for 
everyone.  
Meta is also seeing lots of opportunities for the development of technologi es. Historical research 
shows how the experience can be opened to wider audiences, and how AR/VR technologies are being 
leveraged. Priorities continue to be engaging with the perspectives of communities around the globe 117 
 and these include improving and prov iding services, to give access to markets and information for 
people with disabilities.  
It is extremely important to engage in regulatory and policy environments with academics, 
policymakers, and other sectors of society. Meta learns from groups represen ting those with 
disabilities, to prioritize how to make product improvements. Participating in this work is useful, 
especially to understand and exchange information related to technology and regulatory trends.  
Meta also co -founded and is still active in  Teach Access, a multistakeholder initiative to work in higher 
education to support students before going into tertiary education. Teach Access has won multiple 
awards and has grown to 400+ organizations.  Teach Access and Meta are working with other 
compa nies to drive legislation in the broader ecosystem, such as the WWW consortium, to collaborate 
to improve accessibility standards, keep the dialogue going and ultimately expand Teach Access more 
actively in other parts of the globe.  
Together with Teach A ccess, there are also digital literacy programs to help empower people by 
teaching them how and why to use the internet. Meta has developed a digital citizen program - Get 
Digital – which teaches a range of basic to advanced skills such as online safety sk ills to lesson plans 
that teachers can use.  Meta also partners with many different telco operators on digital literacy 
programs for consumers.   
It is widely understood that indigenous and other groups that tend to live in more rural locations, 
without  strong broadband, will not be able to access many new technologies and features that will 
allow for improved accessibility. Meta argues that having broadband access is foundational to opening 
up a range of new accessible technologies and features.   Meta h as been collaborating with partners 
across the globe, to bring broadband access and new business models to unserved and underserved 
places. In conclusion, we should all engage with government regulators on this to improve 
connectivity.  
 
References  
[129] https://www.yo utube.com/watch?v=pKjROs35Xe4  
[130] https://youtu.be/iuNzi9HZGWk  
[131] https://youtu.be/wFL2l6tjt7M118 
 16. C onference Organisers  
119 
 17. Confere nce Volunteers  
 
